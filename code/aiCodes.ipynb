{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "id": "XUko0oyQSSBu",
    "outputId": "cb6cd8a8-868d-4ed0-8d23-6e2b08655d50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Representation: {'A': ['C'], 'C': ['A', 'E'], 'B': ['D'], 'D': ['B', 'E'], 'E': ['C', 'D']}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the starting node for DFS:  A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFS Traversal:\n",
      "A C E D B "
     ]
    }
   ],
   "source": [
    "#########################    EXP1      #####################\n",
    "'''Implement Recursive Depth First Search Algorithm. Read the undirected\n",
    "unweighted graph from a .csv file. '''\n",
    "import pandas as pd\n",
    "\n",
    "# Function to read the graph from a CSV file\n",
    "def read_graph_from_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    graph = {}\n",
    "    for i in range(len(df)):\n",
    "        node1 = df.iloc[i, 0]\n",
    "        node2 = df.iloc[i, 1]\n",
    "        if node1 not in graph:\n",
    "            graph[node1] = []\n",
    "        if node2 not in graph:\n",
    "            graph[node2] = []\n",
    "        graph[node1].append(node2)\n",
    "        graph[node2].append(node1)  # Because the graph is undirected\n",
    "    return graph\n",
    "\n",
    "# Recursive DFS function\n",
    "def dfs_recursive(graph, node, visited):\n",
    "    if node not in visited:\n",
    "        print(node, end=\" \")\n",
    "        visited.add(node)\n",
    "        for neighbor in graph[node]:\n",
    "            dfs_recursive(graph, neighbor, visited)\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Specify file name manually\n",
    "    file_name = \"C:\\\\Users\\\\shank\\\\Downloads\\\\csvforExp1.csv\"  # <-- Put your actual file name here\n",
    "    \n",
    "    # Read the graph from the uploaded CSV file\n",
    "    graph = read_graph_from_csv(file_name)\n",
    "    \n",
    "    print(\"Graph Representation:\", graph)\n",
    "    \n",
    "    # Ask for the starting node from the user\n",
    "    start_node = input(\"Enter the starting node for DFS: \")\n",
    "    \n",
    "    # Perform DFS traversal\n",
    "    print(\"DFS Traversal:\")\n",
    "    dfs_recursive(graph, start_node, set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_XepIZCVcZB",
    "outputId": "78ad41c9-7ed1-4811-da4b-59afa158024f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter edges of the graph in the format 'node1 node2'. Type 'done' when finished.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter an edge (node1 node2):  a b\n",
      "Enter an edge (node1 node2):  a c\n",
      "Enter an edge (node1 node2):  b d\n",
      "Enter an edge (node1 node2):  b e\n",
      "Enter an edge (node1 node2):  c f\n",
      "Enter an edge (node1 node2):  done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Representation: {'a': ['b', 'c'], 'b': ['a', 'd', 'e'], 'c': ['a', 'f'], 'd': ['b'], 'e': ['b'], 'f': ['c']}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the starting node for DFS:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DFS Traversal (Non-Recursive):\n",
      "a c f b e d "
     ]
    }
   ],
   "source": [
    "#########################    EXP2      #####################\n",
    "'''Implement Non-Recursive Depth First Search Algorithm. Read the\n",
    "undirected unweighted graph from user. \n",
    "'''\n",
    "# Function to read the graph from user input\n",
    "def read_graph_from_user():\n",
    "    graph = {}\n",
    "    print(\"Enter edges of the graph in the format 'node1 node2'. Type 'done' when finished.\")\n",
    "    while True:\n",
    "        edge = input(\"Enter an edge (node1 node2): \")\n",
    "        if edge.lower() == 'done':\n",
    "            break\n",
    "        node1, node2 = edge.split()\n",
    "\n",
    "        # Add nodes to the graph\n",
    "        if node1 not in graph:\n",
    "            graph[node1] = []\n",
    "        if node2 not in graph:\n",
    "            graph[node2] = []\n",
    "\n",
    "        graph[node1].append(node2)\n",
    "        graph[node2].append(node1)  # Undirected graph: add both directions\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Non-recursive DFS function using stack\n",
    "def dfs_non_recursive(graph, start_node):\n",
    "    visited = set()  # To track visited nodes\n",
    "    stack = [start_node]  # Initialize stack with the start node\n",
    "\n",
    "    while stack:\n",
    "        node = stack.pop()  # Pop the last node from the stack\n",
    "\n",
    "        if node not in visited:\n",
    "            print(node, end=\" \")  # Print the node as we visit it\n",
    "            visited.add(node)  # Mark the node as visited\n",
    "\n",
    "            # Add all unvisited neighbors to the stack\n",
    "            for neighbor in graph[node]:\n",
    "                if neighbor not in visited:\n",
    "                    stack.append(neighbor)\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the graph from the user\n",
    "    graph = read_graph_from_user()\n",
    "\n",
    "    print(\"Graph Representation:\", graph)\n",
    "\n",
    "    # Ask for the starting node from the user\n",
    "    start_node = input(\"Enter the starting node for DFS: \")\n",
    "\n",
    "    # Perform DFS traversal\n",
    "    print(\"DFS Traversal (Non-Recursive):\")\n",
    "    dfs_non_recursive(graph, start_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbltIDiuWsUp",
    "outputId": "e51809ea-37a2-48b1-cd1f-137c243e61e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter edges of the graph in the format 'node1 node2'. Type 'done' when finished.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter an edge (node1 node2):  a b\n",
      "Enter an edge (node1 node2):  a c\n",
      "Enter an edge (node1 node2):  b d\n",
      "Enter an edge (node1 node2):  b e\n",
      "Enter an edge (node1 node2):  c f\n",
      "Enter an edge (node1 node2):  done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Representation: {'a': ['b', 'c'], 'b': ['a', 'd', 'e'], 'c': ['a', 'f'], 'd': ['b'], 'e': ['b'], 'f': ['c']}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the starting node for BFS:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BFS Traversal:\n",
      "a b c d e f "
     ]
    }
   ],
   "source": [
    "#########################    EXP3      #####################\n",
    "''' Implement Breadth First Search Algorithm. Read the undirected\n",
    "unweighted graph from user. \n",
    "'''\n",
    "\n",
    "# Function to read the graph from user input\n",
    "def read_graph_from_user():\n",
    "    graph = {}\n",
    "    print(\"Enter edges of the graph in the format 'node1 node2'. Type 'done' when finished.\")\n",
    "    while True:\n",
    "        edge = input(\"Enter an edge (node1 node2): \")\n",
    "        if edge.lower() == 'done':\n",
    "            break\n",
    "        node1, node2 = edge.split()\n",
    "\n",
    "        # Add nodes to the graph\n",
    "        if node1 not in graph:\n",
    "            graph[node1] = []\n",
    "        if node2 not in graph:\n",
    "            graph[node2] = []\n",
    "\n",
    "        graph[node1].append(node2)\n",
    "        graph[node2].append(node1)  # Undirected graph: add both directions\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Breadth First Search function using queue\n",
    "def bfs(graph, start_node):\n",
    "    visited = set()  # To track visited nodes\n",
    "    queue = [start_node]  # Initialize queue with the start node\n",
    "\n",
    "    while queue:\n",
    "        node = queue.pop(0)  # Dequeue the front node from the queue\n",
    "\n",
    "        if node not in visited:\n",
    "            print(node, end=\" \")  # Print the node as we visit it\n",
    "            visited.add(node)  # Mark the node as visited\n",
    "\n",
    "            # Add all unvisited neighbors to the queue\n",
    "            for neighbor in graph[node]:\n",
    "                if neighbor not in visited:\n",
    "                    queue.append(neighbor)\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the graph from the user\n",
    "    graph = read_graph_from_user()\n",
    "\n",
    "    print(\"Graph Representation:\", graph)\n",
    "\n",
    "    # Ask for the starting node from the user\n",
    "    start_node = input(\"Enter the starting node for BFS: \")\n",
    "\n",
    "    # Perform BFS traversal\n",
    "    print(\"BFS Traversal:\")\n",
    "    bfs(graph, start_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i2jXnnLcXkzI",
    "outputId": "9dac2abe-46f8-4dee-c601-1d07c15a7c44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter edges of the graph in the format 'node1 node2'. Type 'done' when finished.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter an edge (node1 node2):  a b\n",
      "Enter an edge (node1 node2):  a c\n",
      "Enter an edge (node1 node2):  b d\n",
      "Enter an edge (node1 node2):  c d\n",
      "Enter an edge (node1 node2):  done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter heuristic values for each node.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter heuristic value for d:  3\n",
      "Enter heuristic value for a:  2\n",
      "Enter heuristic value for b:  1\n",
      "Enter heuristic value for c:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Representation: {'a': ['b', 'c'], 'b': ['d'], 'c': ['d'], 'd': []}\n",
      "Heuristic Values: {'d': 3.0, 'a': 2.0, 'b': 1.0, 'c': 0.0}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the starting node for Best First Search:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best First Search Traversal:\n",
      "a c b d "
     ]
    }
   ],
   "source": [
    "#########################    EXP4      #####################\n",
    "''' Implement Best First Search Algorithm. Read the directed unweighted\n",
    "graph and the heuristic values from user.'''\n",
    "\n",
    "import heapq  # For the priority queue (min-heap)\n",
    "\n",
    "# Function to read the graph and heuristic values from user input\n",
    "def read_graph_and_heuristics():\n",
    "    graph = {}\n",
    "    heuristics = {}\n",
    "\n",
    "    print(\"Enter edges of the graph in the format 'node1 node2'. Type 'done' when finished.\")\n",
    "    while True:\n",
    "        edge = input(\"Enter an edge (node1 node2): \")\n",
    "        if edge.lower() == 'done':\n",
    "            break\n",
    "        node1, node2 = edge.split()\n",
    "\n",
    "        if node1 not in graph:\n",
    "            graph[node1] = []\n",
    "        graph[node1].append(node2)  # Directed edge from node1 to node2\n",
    "\n",
    "        if node2 not in graph:\n",
    "            graph[node2] = []  # Make sure to add node2 as well in case it's not there\n",
    "\n",
    "    print(\"Enter heuristic values for each node.\")\n",
    "    # Automatically ask for heuristic values for all nodes present in the graph\n",
    "    all_nodes = set(graph.keys())\n",
    "    for node in all_nodes:\n",
    "        if node not in heuristics:\n",
    "            heuristic = float(input(f\"Enter heuristic value for {node}: \"))\n",
    "            heuristics[node] = heuristic\n",
    "\n",
    "    return graph, heuristics\n",
    "\n",
    "# Best First Search algorithm using a priority queue (min-heap)\n",
    "def best_first_search(graph, heuristics, start_node):\n",
    "    visited = set()  # To track visited nodes\n",
    "    priority_queue = []  # Priority queue to explore nodes based on heuristic\n",
    "\n",
    "    # Push the start node with its heuristic value to the queue\n",
    "    heapq.heappush(priority_queue, (heuristics[start_node], start_node))\n",
    "\n",
    "    while priority_queue:\n",
    "        _, current_node = heapq.heappop(priority_queue)  # Get the node with the lowest heuristic value\n",
    "\n",
    "        if current_node not in visited:\n",
    "            print(current_node, end=\" \")  # Print the node as we visit it\n",
    "            visited.add(current_node)  # Mark it as visited\n",
    "\n",
    "            # Add unvisited neighbors to the priority queue\n",
    "            for neighbor in graph.get(current_node, []):\n",
    "                if neighbor not in visited:\n",
    "                    heapq.heappush(priority_queue, (heuristics[neighbor], neighbor))\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the graph and heuristics from the user\n",
    "    graph, heuristics = read_graph_and_heuristics()\n",
    "\n",
    "    print(\"Graph Representation:\", graph)\n",
    "    print(\"Heuristic Values:\", heuristics)\n",
    "\n",
    "    # Ask for the starting node from the user\n",
    "    start_node = input(\"Enter the starting node for Best First Search: \")\n",
    "\n",
    "    # Perform Best First Search traversal\n",
    "    print(\"Best First Search Traversal:\")\n",
    "    best_first_search(graph, heuristics, start_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iq6uNsVWYQAR",
    "outputId": "539de06f-3248-4d01-878f-28eab6d5d667"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter edges of the graph in the format 'node1 node2 weight'. Type 'done' when finished.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter an edge (node1 node2 weight):  a b 1\n",
      "Enter an edge (node1 node2 weight):  a c 3\n",
      "Enter an edge (node1 node2 weight):  b d 2\n",
      "Enter an edge (node1 node2 weight):  c d 1\n",
      "Enter an edge (node1 node2 weight):  done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter heuristic values for each node.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter heuristic value for d:  3\n",
      "Enter heuristic value for a:  2\n",
      "Enter heuristic value for b:  1\n",
      "Enter heuristic value for c:  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Representation: {'a': [('b', 1.0), ('c', 3.0)], 'b': [('a', 1.0), ('d', 2.0)], 'c': [('a', 3.0), ('d', 1.0)], 'd': [('b', 2.0), ('c', 1.0)]}\n",
      "Heuristic Values: {'d': 3.0, 'a': 2.0, 'b': 1.0, 'c': 0.0}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the starting node for Best First Search:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best First Search Traversal:\n",
      "a c b d "
     ]
    }
   ],
   "source": [
    "#########################    EXP5      #####################\n",
    "''' Implement Best First Search Algorithm. Read the undirected weighted\n",
    "graph and the heuristic values from user. \n",
    "'''\n",
    "\n",
    "import heapq  # For the priority queue (min-heap)\n",
    "\n",
    "# Function to read the graph and heuristic values from user input\n",
    "def read_graph_and_heuristics():\n",
    "    graph = {}\n",
    "    heuristics = {}\n",
    "\n",
    "    print(\"Enter edges of the graph in the format 'node1 node2 weight'. Type 'done' when finished.\")\n",
    "    while True:\n",
    "        edge = input(\"Enter an edge (node1 node2 weight): \")\n",
    "        if edge.lower() == 'done':\n",
    "            break\n",
    "        node1, node2, weight = edge.split()\n",
    "        weight = float(weight)\n",
    "\n",
    "        if node1 not in graph:\n",
    "            graph[node1] = []\n",
    "        if node2 not in graph:\n",
    "            graph[node2] = []\n",
    "\n",
    "        # Since the graph is undirected, add both directions\n",
    "        graph[node1].append((node2, weight))\n",
    "        graph[node2].append((node1, weight))\n",
    "\n",
    "    print(\"Enter heuristic values for each node.\")\n",
    "    # Automatically ask for heuristic values for all nodes present in the graph\n",
    "    all_nodes = set(graph.keys())\n",
    "    for node in all_nodes:\n",
    "        if node not in heuristics:\n",
    "            heuristic = float(input(f\"Enter heuristic value for {node}: \"))\n",
    "            heuristics[node] = heuristic\n",
    "\n",
    "    return graph, heuristics\n",
    "\n",
    "# Best First Search algorithm using a priority queue (min-heap)\n",
    "def best_first_search(graph, heuristics, start_node):\n",
    "    visited = set()  # To track visited nodes\n",
    "    priority_queue = []  # Priority queue to explore nodes based on heuristic\n",
    "\n",
    "    # Push the start node with its heuristic value to the queue\n",
    "    heapq.heappush(priority_queue, (heuristics[start_node], start_node))\n",
    "\n",
    "    while priority_queue:\n",
    "        _, current_node = heapq.heappop(priority_queue)  # Get the node with the lowest heuristic value\n",
    "\n",
    "        if current_node not in visited:\n",
    "            print(current_node, end=\" \")  # Print the node as we visit it\n",
    "            visited.add(current_node)  # Mark it as visited\n",
    "\n",
    "            # Add unvisited neighbors to the priority queue based on heuristic values\n",
    "            for neighbor, _ in graph.get(current_node, []):\n",
    "                if neighbor not in visited:\n",
    "                    heapq.heappush(priority_queue, (heuristics[neighbor], neighbor))\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the graph and heuristics from the user\n",
    "    graph, heuristics = read_graph_and_heuristics()\n",
    "\n",
    "    print(\"Graph Representation:\", graph)\n",
    "    print(\"Heuristic Values:\", heuristics)\n",
    "\n",
    "    # Ask for the starting node from the user\n",
    "    start_node = input(\"Enter the starting node for Best First Search: \")\n",
    "\n",
    "    # Perform Best First Search traversal\n",
    "    print(\"Best First Search Traversal:\")\n",
    "    best_first_search(graph, heuristics, start_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4QFwA24KajsQ",
    "outputId": "dbbc6ea2-e922-4d87-a9e0-bb5f1f654c5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the edges of the graph:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter an edge (node1 node2) or 'done' to finish:  a b\n",
      "Enter an edge (node1 node2) or 'done' to finish:  a c\n",
      "Enter an edge (node1 node2) or 'done' to finish:  b d\n",
      "Enter an edge (node1 node2) or 'done' to finish:  done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the heuristic values for each node:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter node for heuristic value or 'done' to finish:  a\n",
      "Enter heuristic value for a:  3\n",
      "Enter node for heuristic value or 'done' to finish:  b\n",
      "Enter heuristic value for b:  2\n",
      "Enter node for heuristic value or 'done' to finish:  c\n",
      "Enter heuristic value for c:  1\n",
      "Enter node for heuristic value or 'done' to finish:  done\n",
      "Enter the starting node for Best First Search:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best First Search Traversal:\n",
      "a c b d "
     ]
    }
   ],
   "source": [
    "#########################    EXP6      #####################\n",
    "''' Implement Best First Search Algorithm. Read the undirected unweighted\n",
    "graph and the heuristic values from user. \n",
    "'''\n",
    "import heapq\n",
    "\n",
    "# Function for Best First Search traversal\n",
    "def best_first_search(graph, heuristics, start_node):\n",
    "    # Priority queue to store nodes with their heuristic values\n",
    "    priority_queue = []\n",
    "\n",
    "    # Add the starting node with its heuristic value to the queue\n",
    "    heapq.heappush(priority_queue, (heuristics.get(start_node, float('inf')), start_node))\n",
    "\n",
    "    visited = set()\n",
    "\n",
    "    while priority_queue:\n",
    "        # Get the node with the smallest heuristic value\n",
    "        current_heuristic, current_node = heapq.heappop(priority_queue)\n",
    "\n",
    "        # If the node is already visited, skip it\n",
    "        if current_node in visited:\n",
    "            continue\n",
    "\n",
    "        # Visit the node\n",
    "        print(current_node, end=\" \")\n",
    "        visited.add(current_node)\n",
    "\n",
    "        # Add unvisited neighbors to the queue based on their heuristic values\n",
    "        for neighbor in graph.get(current_node, []):\n",
    "            if neighbor not in visited:\n",
    "                # Use the heuristic value from the input or assign float('inf') if not present\n",
    "                heapq.heappush(priority_queue, (heuristics.get(neighbor, float('inf')), neighbor))\n",
    "\n",
    "# Read graph from user input\n",
    "def read_graph():\n",
    "    graph = {}\n",
    "    while True:\n",
    "        edge = input(\"Enter an edge (node1 node2) or 'done' to finish: \").strip()\n",
    "        if edge.lower() == 'done':\n",
    "            break\n",
    "        node1, node2 = edge.split()\n",
    "\n",
    "        # Add the edge to the graph\n",
    "        if node1 not in graph:\n",
    "            graph[node1] = []\n",
    "        if node2 not in graph:\n",
    "            graph[node2] = []\n",
    "        graph[node1].append(node2)\n",
    "        graph[node2].append(node1)\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Read heuristic values from user input\n",
    "def read_heuristics():\n",
    "    heuristics = {}\n",
    "    while True:\n",
    "        node = input(\"Enter node for heuristic value or 'done' to finish: \").strip()\n",
    "        if node.lower() == 'done':\n",
    "            break\n",
    "        heuristic_value = float(input(f\"Enter heuristic value for {node}: \").strip())\n",
    "        heuristics[node] = heuristic_value\n",
    "    return heuristics\n",
    "\n",
    "# Main function to execute the Best First Search\n",
    "def main():\n",
    "    print(\"Enter the edges of the graph:\")\n",
    "    graph = read_graph()\n",
    "\n",
    "    print(\"Enter the heuristic values for each node:\")\n",
    "    heuristics = read_heuristics()\n",
    "\n",
    "    start_node = input(\"Enter the starting node for Best First Search: \").strip()\n",
    "\n",
    "    print(\"\\nBest First Search Traversal:\")\n",
    "    best_first_search(graph, heuristics, start_node)\n",
    "\n",
    "# Run the program\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9HXyyW8ubhTZ",
    "outputId": "a1a130da-9590-46f1-fb0d-bed75c0492a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the directed weighted edges of the graph:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter an edge (node1 node2 weight) or 'done' to finish:  a b 1\n",
      "Enter an edge (node1 node2 weight) or 'done' to finish:  a c 3\n",
      "Enter an edge (node1 node2 weight) or 'done' to finish:  b d 2\n",
      "Enter an edge (node1 node2 weight) or 'done' to finish:  c d 1\n",
      "Enter an edge (node1 node2 weight) or 'done' to finish:  done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the heuristic values for each node:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter node for heuristic value or 'done' to finish:  a\n",
      "Enter heuristic value for a:  3\n",
      "Enter node for heuristic value or 'done' to finish:  b\n",
      "Enter heuristic value for b:  2\n",
      "Enter node for heuristic value or 'done' to finish:  c\n",
      "Enter heuristic value for c:  1\n",
      "Enter node for heuristic value or 'done' to finish:  d\n",
      "Enter heuristic value for d:  0\n",
      "Enter node for heuristic value or 'done' to finish:  done\n",
      "Enter the starting node for Best First Search:  a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best First Search Traversal:\n",
      "a c d b "
     ]
    }
   ],
   "source": [
    "#########################    EXP7      #####################\n",
    "'''Implement Best First Search Algorithm. Read the directed weighted graph\n",
    "and the heuristic values from user. '''\n",
    "\n",
    "import heapq\n",
    "\n",
    "# Function for Best First Search traversal on directed weighted graph\n",
    "def best_first_search(graph, heuristics, start_node):\n",
    "    # Priority queue to store nodes with their heuristic values\n",
    "    priority_queue = []\n",
    "\n",
    "    # Add the starting node with its heuristic value to the queue\n",
    "    heapq.heappush(priority_queue, (heuristics.get(start_node, float('inf')), start_node))\n",
    "\n",
    "    visited = set()\n",
    "\n",
    "    while priority_queue:\n",
    "        # Get the node with the smallest heuristic value\n",
    "        current_heuristic, current_node = heapq.heappop(priority_queue)\n",
    "\n",
    "        # If the node is already visited, skip it\n",
    "        if current_node in visited:\n",
    "            continue\n",
    "\n",
    "        # Visit the node\n",
    "        print(current_node, end=\" \")\n",
    "        visited.add(current_node)\n",
    "\n",
    "        # Add unvisited neighbors to the queue based on their heuristic values\n",
    "        for neighbor, _ in graph.get(current_node, []):  # Ignore the weight, only use neighbors\n",
    "            if neighbor not in visited:\n",
    "                # Use the heuristic value from the input or assign float('inf') if not present\n",
    "                heapq.heappush(priority_queue, (heuristics.get(neighbor, float('inf')), neighbor))\n",
    "\n",
    "# Read directed weighted graph from user input\n",
    "def read_graph():\n",
    "    graph = {}\n",
    "    while True:\n",
    "        edge = input(\"Enter an edge (node1 node2 weight) or 'done' to finish: \").strip()\n",
    "        if edge.lower() == 'done':\n",
    "            break\n",
    "        node1, node2, weight = edge.split()\n",
    "        weight = float(weight)\n",
    "\n",
    "        # Add the directed edge to the graph\n",
    "        if node1 not in graph:\n",
    "            graph[node1] = []\n",
    "        graph[node1].append((node2, weight))\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Read heuristic values from user input\n",
    "def read_heuristics():\n",
    "    heuristics = {}\n",
    "    while True:\n",
    "        node = input(\"Enter node for heuristic value or 'done' to finish: \").strip()\n",
    "        if node.lower() == 'done':\n",
    "            break\n",
    "        heuristic_value = float(input(f\"Enter heuristic value for {node}: \").strip())\n",
    "        heuristics[node] = heuristic_value\n",
    "    return heuristics\n",
    "\n",
    "# Main function to execute the Best First Search\n",
    "def main():\n",
    "    print(\"Enter the directed weighted edges of the graph:\")\n",
    "    graph = read_graph()\n",
    "\n",
    "    print(\"Enter the heuristic values for each node:\")\n",
    "    heuristics = read_heuristics()\n",
    "\n",
    "    start_node = input(\"Enter the starting node for Best First Search: \").strip()\n",
    "\n",
    "    print(\"\\nBest First Search Traversal:\")\n",
    "    best_first_search(graph, heuristics, start_node)\n",
    "\n",
    "# Run the program\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hZ4kGweDecrn",
    "outputId": "59f244dc-58b0-4191-fc13-71f239862d0d"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the path of the graph CSV file:  C:\\Users\\shank\\Downloads\\csvforExp8Graph.csv\n",
      "Enter the path of the heuristic CSV file:  C:\\Users\\shank\\Downloads\\csvforExp8Heru.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Graph Representation:\n",
      "  a -> [('b', 1.0), ('c', 3.0)]\n",
      "  b -> [('d', 2.0)]\n",
      "  c -> [('d', 1.0)]\n",
      "\n",
      "Heuristic Values:\n",
      "  a: 3.0\n",
      "  b: 2.0\n",
      "  c: 1.0\n",
      "  d: 0.0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the starting node for A* Search:  a\n",
      "Enter the goal node for A* Search:  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "A* Search Results:\n",
      "Path: a -> b -> d\n",
      "Total Cost: 3.0\n",
      "\n",
      "Step-by-step node evaluation:\n",
      "  a to b: g=1.0, h=2.0, f=3.0\n",
      "  b to d: g=3.0, h=0.0, f=3.0\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP8      #####################\n",
    "\n",
    "#A* directed weighted graph and heuristic csv\n",
    "\n",
    "import csv\n",
    "import heapq\n",
    "\n",
    "# Function to read graph from CSV file\n",
    "def read_graph_from_csv(graph_file, heuristic_file):\n",
    "    graph = {}\n",
    "    heuristics = {}\n",
    "\n",
    "    # Read graph data (edges with weights)\n",
    "    with open(graph_file, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            node1 = row['node1']\n",
    "            node2 = row['node2']\n",
    "            weight = float(row['weight'])\n",
    "\n",
    "            if node1 not in graph:\n",
    "                graph[node1] = []\n",
    "            graph[node1].append((node2, weight))\n",
    "\n",
    "    # Read heuristic values\n",
    "    with open(heuristic_file, 'r') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        for row in reader:\n",
    "            node = row['node']\n",
    "            heuristic = float(row['heuristic_value'])\n",
    "            heuristics[node] = heuristic\n",
    "\n",
    "    return graph, heuristics\n",
    "\n",
    "# A* Algorithm\n",
    "def a_star_algorithm(graph, heuristics, start, goal):\n",
    "    open_list = []  # Priority queue (min-heap)\n",
    "    heapq.heappush(open_list, (heuristics[start], 0, start))  # (f(n), tiebreaker, node)\n",
    "\n",
    "    g_costs = {start: 0}  # g(n): cost from start to current node\n",
    "    came_from = {}  # To reconstruct the path\n",
    "\n",
    "    visited = set()  # Keep track of visited nodes\n",
    "    count = 0  # Tiebreaker for equal f-values\n",
    "\n",
    "    while open_list:\n",
    "        _, _, current_node = heapq.heappop(open_list)\n",
    "\n",
    "        if current_node in visited:\n",
    "            continue\n",
    "\n",
    "        visited.add(current_node)\n",
    "\n",
    "        if current_node == goal:\n",
    "            # Reconstruct the path\n",
    "            path = []\n",
    "            while current_node in came_from:\n",
    "                path.append(current_node)\n",
    "                current_node = came_from[current_node]\n",
    "            path.append(start)\n",
    "            path.reverse()\n",
    "            return path, g_costs[goal]  # Return path and total cost\n",
    "\n",
    "        for neighbor, weight in graph.get(current_node, []):\n",
    "            if neighbor in visited:\n",
    "                continue\n",
    "\n",
    "            tentative_g_cost = g_costs[current_node] + weight\n",
    "\n",
    "            if neighbor not in g_costs or tentative_g_cost < g_costs[neighbor]:\n",
    "                g_costs[neighbor] = tentative_g_cost\n",
    "                f_cost = tentative_g_cost + heuristics.get(neighbor, 0)\n",
    "                count += 1  # Ensure unique ordering in the heap\n",
    "                heapq.heappush(open_list, (f_cost, count, neighbor))\n",
    "                came_from[neighbor] = current_node\n",
    "\n",
    "    return None, float('inf')  # No path found\n",
    "\n",
    "# Main Execution\n",
    "def main():\n",
    "    try:\n",
    "        # Take the file paths from the user\n",
    "        graph_file = input(\"Enter the path of the graph CSV file: \")\n",
    "        heuristic_file = input(\"Enter the path of the heuristic CSV file: \")\n",
    "\n",
    "        # Read graph and heuristic data from the provided files\n",
    "        graph, heuristics = read_graph_from_csv(graph_file, heuristic_file)\n",
    "\n",
    "        print(\"\\nGraph Representation:\")\n",
    "        for node, neighbors in graph.items():\n",
    "            print(f\"  {node} -> {neighbors}\")\n",
    "\n",
    "        print(\"\\nHeuristic Values:\")\n",
    "        for node, value in heuristics.items():\n",
    "            print(f\"  {node}: {value}\")\n",
    "\n",
    "        # Get start and goal nodes from user\n",
    "        start_node = input(\"\\nEnter the starting node for A* Search: \")\n",
    "        goal_node = input(\"Enter the goal node for A* Search: \")\n",
    "\n",
    "        # Validate start and goal nodes\n",
    "        if start_node not in graph:\n",
    "            print(f\"Error: Start node '{start_node}' is not in the graph!\")\n",
    "            return\n",
    "        if goal_node not in heuristics:\n",
    "            print(f\"Error: Goal node '{goal_node}' is not in the graph!\")\n",
    "            return\n",
    "\n",
    "        # Perform A* Search\n",
    "        path, total_cost = a_star_algorithm(graph, heuristics, start_node, goal_node)\n",
    "\n",
    "        if path:\n",
    "            print(\"\\nA* Search Results:\")\n",
    "            print(\"Path:\", \" -> \".join(path))\n",
    "            print(\"Total Cost:\", total_cost)\n",
    "\n",
    "            # Show step-by-step evaluation\n",
    "            print(\"\\nStep-by-step node evaluation:\")\n",
    "            current_cost = 0\n",
    "            for i in range(len(path)-1):\n",
    "                current = path[i]\n",
    "                next_node = path[i+1]\n",
    "                for neighbor, weight in graph.get(current, []):\n",
    "                    if neighbor == next_node:\n",
    "                        node_cost = weight\n",
    "                        current_cost += node_cost\n",
    "                        break\n",
    "\n",
    "                print(f\"  {current} to {next_node}: g={current_cost}, h={heuristics[next_node]}, f={current_cost + heuristics[next_node]}\")\n",
    "        else:\n",
    "            print(\"\\nNo path found from\", start_node, \"to\", goal_node)\n",
    "\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: File not found - {e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Run the program\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V1-xqydqlQr4",
    "outputId": "7fb18aa5-60d1-4215-db87-2a893a0d7406"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the directed weighted edges of the graph:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter an edge (node1 node2 weight) or 'done' to finish:  a b 1\n",
      "Enter an edge (node1 node2 weight) or 'done' to finish:  a c 3\n",
      "Enter an edge (node1 node2 weight) or 'done' to finish:  b d 2\n",
      "Enter an edge (node1 node2 weight) or 'done' to finish:  c d 1\n",
      "Enter an edge (node1 node2 weight) or 'done' to finish:  done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the heuristic values for each node:\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter node for heuristic value or 'done' to finish:  a\n",
      "Enter heuristic value for a:  3\n",
      "Enter node for heuristic value or 'done' to finish:  b\n",
      "Enter heuristic value for b:  2\n",
      "Enter node for heuristic value or 'done' to finish:  c\n",
      "Enter heuristic value for c:  1\n",
      "Enter node for heuristic value or 'done' to finish:  d\n",
      "Enter heuristic value for d:  0\n",
      "Enter node for heuristic value or 'done' to finish:  done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Representation: {'a': [('b', 1.0), ('c', 3.0)], 'b': [('d', 2.0)], 'c': [('d', 1.0)]}\n",
      "Heuristic Values: {'a': 3.0, 'b': 2.0, 'c': 1.0, 'd': 0.0}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the starting node for A* Search:  a\n",
      "Enter the goal node for A* Search:  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A* Search Path: a -> b -> d\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP9      #####################\n",
    "\n",
    "# A* directed weighted graph and heuristic from user\n",
    "\n",
    "import heapq\n",
    "\n",
    "# A* Algorithm\n",
    "def a_star_algorithm(graph, heuristics, start, goal):\n",
    "    open_list = []  # Priority queue (min-heap)\n",
    "    heapq.heappush(open_list, (heuristics[start], start))  # (f(n), node)\n",
    "\n",
    "    g_costs = {start: 0}  # g(n): cost from start to current node\n",
    "    came_from = {}  # To reconstruct the path\n",
    "\n",
    "    while open_list:\n",
    "        _, current_node = heapq.heappop(open_list)\n",
    "\n",
    "        if current_node == goal:\n",
    "            # Reconstruct the path\n",
    "            path = []\n",
    "            while current_node in came_from:\n",
    "                path.append(current_node)\n",
    "                current_node = came_from[current_node]\n",
    "            path.append(start)\n",
    "            path.reverse()\n",
    "            return path\n",
    "\n",
    "        for neighbor, weight in graph.get(current_node, []):\n",
    "            tentative_g_cost = g_costs[current_node] + weight\n",
    "\n",
    "            if neighbor not in g_costs or tentative_g_cost < g_costs[neighbor]:\n",
    "                g_costs[neighbor] = tentative_g_cost\n",
    "                f_cost = tentative_g_cost + heuristics.get(neighbor, 0)\n",
    "                heapq.heappush(open_list, (f_cost, neighbor))\n",
    "                came_from[neighbor] = current_node\n",
    "\n",
    "    return None  # No path found\n",
    "\n",
    "# Function to read the graph and heuristics from user input\n",
    "def read_graph_and_heuristics():\n",
    "    graph = {}\n",
    "    heuristics = {}\n",
    "\n",
    "    # Read the graph (directed weighted edges)\n",
    "    print(\"Enter the directed weighted edges of the graph:\")\n",
    "    while True:\n",
    "        edge = input(\"Enter an edge (node1 node2 weight) or 'done' to finish: \")\n",
    "        if edge == 'done':\n",
    "            break\n",
    "        node1, node2, weight = edge.split()\n",
    "        weight = float(weight)\n",
    "        if node1 not in graph:\n",
    "            graph[node1] = []\n",
    "        graph[node1].append((node2, weight))\n",
    "\n",
    "    # Read heuristic values\n",
    "    print(\"Enter the heuristic values for each node:\")\n",
    "    while True:\n",
    "        node = input(\"Enter node for heuristic value or 'done' to finish: \")\n",
    "        if node == 'done':\n",
    "            break\n",
    "        heuristic = float(input(f\"Enter heuristic value for {node}: \"))\n",
    "        heuristics[node] = heuristic\n",
    "\n",
    "    return graph, heuristics\n",
    "\n",
    "# Main Execution\n",
    "def main():\n",
    "    # Read the graph and heuristics from user input\n",
    "    graph, heuristics = read_graph_and_heuristics()\n",
    "\n",
    "    print(\"Graph Representation:\", graph)\n",
    "    print(\"Heuristic Values:\", heuristics)\n",
    "\n",
    "    # Get start and goal nodes from user\n",
    "    start_node = input(\"Enter the starting node for A* Search: \")\n",
    "    goal_node = input(\"Enter the goal node for A* Search: \")\n",
    "\n",
    "    # Perform A* Search\n",
    "    path = a_star_algorithm(graph, heuristics, start_node, goal_node)\n",
    "\n",
    "    if path:\n",
    "        print(\"A* Search Path:\", \" -> \".join(path))\n",
    "    else:\n",
    "        print(\"No path found!\")\n",
    "\n",
    "# Run the program\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7pJR0U0BmW0H",
    "outputId": "55a10f88-b5d4-4baa-cb2d-5434cfefc7ac"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the file path for the graph CSV:  C:\\Users\\shank\\Downloads\\csvforExp8Graph.csv\n",
      "Enter the file path for the heuristics CSV:  C:\\Users\\shank\\Downloads\\csvforExp8Heru.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Representation: {'a': [('b', 1.0), ('c', 3.0)], 'b': [('a', 1.0), ('d', 2.0)], 'c': [('a', 3.0), ('d', 1.0)], 'd': [('b', 2.0), ('c', 1.0)]}\n",
      "Heuristic Values: {'a': 3.0, 'b': 2.0, 'c': 1.0, 'd': 0.0}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the starting node for A* Search:  a\n",
      "Enter the goal node for A* Search:  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A* Search Path: a -> b -> d\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP 10     #####################\n",
    "# A* undirected weighted graph and heuristic csv\n",
    "\n",
    "import pandas as pd\n",
    "import heapq\n",
    "\n",
    "# A* Algorithm\n",
    "def a_star_algorithm(graph, heuristics, start, goal):\n",
    "    open_list = []  # Priority queue (min-heap)\n",
    "    heapq.heappush(open_list, (heuristics[start], start))  # (f(n), node)\n",
    "\n",
    "    g_costs = {start: 0}  # g(n): cost from start to current node\n",
    "    came_from = {}  # To reconstruct the path\n",
    "\n",
    "    while open_list:\n",
    "        _, current_node = heapq.heappop(open_list)\n",
    "\n",
    "        if current_node == goal:\n",
    "            # Reconstruct the path\n",
    "            path = []\n",
    "            while current_node in came_from:\n",
    "                path.append(current_node)\n",
    "                current_node = came_from[current_node]\n",
    "            path.append(start)\n",
    "            path.reverse()\n",
    "            return path\n",
    "\n",
    "        for neighbor, weight in graph.get(current_node, []):\n",
    "            tentative_g_cost = g_costs[current_node] + weight\n",
    "\n",
    "            if neighbor not in g_costs or tentative_g_cost < g_costs[neighbor]:\n",
    "                g_costs[neighbor] = tentative_g_cost\n",
    "                f_cost = tentative_g_cost + heuristics.get(neighbor, 0)\n",
    "                heapq.heappush(open_list, (f_cost, neighbor))\n",
    "                came_from[neighbor] = current_node\n",
    "\n",
    "    return None  # No path found\n",
    "\n",
    "# Function to read the graph from CSV file\n",
    "def read_graph_from_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    graph = {}\n",
    "\n",
    "    # Populate the graph from the edges\n",
    "    for i in range(len(df)):\n",
    "        node1 = df.iloc[i, 0]\n",
    "        node2 = df.iloc[i, 1]\n",
    "        weight = float(df.iloc[i, 2])\n",
    "\n",
    "        if node1 not in graph:\n",
    "            graph[node1] = []\n",
    "        if node2 not in graph:\n",
    "            graph[node2] = []\n",
    "\n",
    "        # Since the graph is undirected, add both directions\n",
    "        graph[node1].append((node2, weight))\n",
    "        graph[node2].append((node1, weight))\n",
    "\n",
    "    return graph\n",
    "\n",
    "# Function to read heuristic values from CSV file\n",
    "def read_heuristics_from_csv(file_path):\n",
    "    df = pd.read_csv(file_path)\n",
    "    heuristics = {}\n",
    "\n",
    "    # Populate the heuristics dictionary\n",
    "    for i in range(len(df)):\n",
    "        node = df.iloc[i, 0]\n",
    "        heuristic_value = float(df.iloc[i, 1])\n",
    "        heuristics[node] = heuristic_value\n",
    "\n",
    "    return heuristics\n",
    "\n",
    "# Main Execution\n",
    "def main():\n",
    "    # Get the paths for the CSV files\n",
    "    graph_file = input(\"Enter the file path for the graph CSV: \")\n",
    "    heuristics_file = input(\"Enter the file path for the heuristics CSV: \")\n",
    "\n",
    "    # Read the graph and heuristics from CSV files\n",
    "    graph = read_graph_from_csv(graph_file)\n",
    "    heuristics = read_heuristics_from_csv(heuristics_file)\n",
    "\n",
    "    print(\"Graph Representation:\", graph)\n",
    "    print(\"Heuristic Values:\", heuristics)\n",
    "\n",
    "    # Get start and goal nodes from user\n",
    "    start_node = input(\"Enter the starting node for A* Search: \")\n",
    "    goal_node = input(\"Enter the goal node for A* Search: \")\n",
    "\n",
    "    # Perform A* Search\n",
    "    path = a_star_algorithm(graph, heuristics, start_node, goal_node)\n",
    "\n",
    "    if path:\n",
    "        print(\"A* Search Path:\", \" -> \".join(path))\n",
    "    else:\n",
    "        print(\"No path found!\")\n",
    "\n",
    "# Run the program\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UvERZKQ9zNun",
    "outputId": "6e28f23d-845d-49db-f15f-f4524c981742"
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter an edge (node1 node2 weight) or 'done' to finish:  a b 1\n",
      "Enter an edge (node1 node2 weight) or 'done' to finish:  a c 2\n",
      "Enter an edge (node1 node2 weight) or 'done' to finish:  b d 3\n",
      "Enter an edge (node1 node2 weight) or 'done' to finish:  c d 1\n",
      "Enter an edge (node1 node2 weight) or 'done' to finish:  done\n",
      "Enter node for heuristic value or 'done' to finish:  a\n",
      "Enter heuristic value for a:  3\n",
      "Enter node for heuristic value or 'done' to finish:  b\n",
      "Enter heuristic value for b:  2\n",
      "Enter node for heuristic value or 'done' to finish:  c\n",
      "Enter heuristic value for c:  1\n",
      "Enter node for heuristic value or 'done' to finish:  d\n",
      "Enter heuristic value for d:  0\n",
      "Enter node for heuristic value or 'done' to finish:  done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph Representation: {'a': [('b', 1.0), ('c', 2.0)], 'b': [('a', 1.0), ('d', 3.0)], 'c': [('a', 2.0), ('d', 1.0)], 'd': [('b', 3.0), ('c', 1.0)]}\n",
      "Heuristic Values: {'a': 3.0, 'b': 2.0, 'c': 1.0, 'd': 0.0}\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the starting node for A* Search:  a\n",
      "Enter the goal node for A* Search:  d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path found: ['a', 'c', 'd']\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP 11     #####################\n",
    "# A* undirected weighted graph and heuristic from user\n",
    "\n",
    "import heapq\n",
    "\n",
    "# Function to perform A* algorithm\n",
    "def a_star_algorithm(graph, heuristics, start, goal):\n",
    "    open_list = []  # Priority queue (min-heap)\n",
    "    heapq.heappush(open_list, (heuristics[start], start))  # (f(n), node)\n",
    "\n",
    "    g_costs = {start: 0}  # g(n): cost from start to current node\n",
    "    f_costs = {start: heuristics[start]}  # f(n) = g(n) + h(n)\n",
    "\n",
    "    came_from = {}  # To reconstruct the path\n",
    "\n",
    "    while open_list:\n",
    "        _, current_node = heapq.heappop(open_list)\n",
    "\n",
    "        if current_node == goal:\n",
    "            # Reconstruct the path\n",
    "            path = []\n",
    "            while current_node in came_from:\n",
    "                path.append(current_node)\n",
    "                current_node = came_from[current_node]\n",
    "            path.append(start)\n",
    "            path.reverse()\n",
    "            return path\n",
    "\n",
    "        for neighbor, weight in graph.get(current_node, []):\n",
    "            tentative_g_cost = g_costs[current_node] + weight\n",
    "\n",
    "            if neighbor not in g_costs or tentative_g_cost < g_costs[neighbor]:\n",
    "                came_from[neighbor] = current_node\n",
    "                g_costs[neighbor] = tentative_g_cost\n",
    "                f_costs[neighbor] = tentative_g_cost + heuristics[neighbor]\n",
    "                heapq.heappush(open_list, (f_costs[neighbor], neighbor))\n",
    "\n",
    "    return None  # No path found\n",
    "\n",
    "# Function to read graph from user input\n",
    "def read_graph():\n",
    "    graph = {}\n",
    "    while True:\n",
    "        edge = input(\"Enter an edge (node1 node2 weight) or 'done' to finish: \")\n",
    "        if edge == 'done':\n",
    "            break\n",
    "        node1, node2, weight = edge.split()\n",
    "        weight = float(weight)  # convert weight to float\n",
    "        if node1 not in graph:\n",
    "            graph[node1] = []\n",
    "        if node2 not in graph:\n",
    "            graph[node2] = []\n",
    "        graph[node1].append((node2, weight))\n",
    "        graph[node2].append((node1, weight))  # Because the graph is undirected\n",
    "    return graph\n",
    "\n",
    "# Function to read heuristic values from user input\n",
    "def read_heuristics():\n",
    "    heuristics = {}\n",
    "    while True:\n",
    "        node = input(\"Enter node for heuristic value or 'done' to finish: \")\n",
    "        if node == 'done':\n",
    "            break\n",
    "        heuristic_value = float(input(f\"Enter heuristic value for {node}: \"))\n",
    "        heuristics[node] = heuristic_value\n",
    "    return heuristics\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Read graph and heuristics from user input\n",
    "    graph = read_graph()\n",
    "    heuristics = read_heuristics()\n",
    "\n",
    "    print(\"Graph Representation:\", graph)\n",
    "    print(\"Heuristic Values:\", heuristics)\n",
    "\n",
    "    # Take the starting and goal nodes from the user\n",
    "    start_node = input(\"Enter the starting node for A* Search: \")\n",
    "    goal_node = input(\"Enter the goal node for A* Search: \")\n",
    "\n",
    "    # Perform A* algorithm and display the path\n",
    "    path = a_star_algorithm(graph, heuristics, start_node, goal_node)\n",
    "    if path:\n",
    "        print(\"Path found:\", path)\n",
    "    else:\n",
    "        print(\"No path found from\", start_node, \"to\", goal_node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1OF-c4lBz7mH",
    "outputId": "46d42102-770c-4793-ee63-64f226cba63d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy Set A: {'x1': 0.3, 'x2': 0.7, 'x3': 0.5}\n",
      "Fuzzy Set B: {'x1': 0.6, 'x2': 0.2, 'x3': 0.8}\n",
      "Fuzzy Set C: {'x1': 0.4, 'x2': 0.9, 'x3': 0.3}\n",
      "\n",
      "Union of A, B, and C: {'x2': 0.9, 'x1': 0.6, 'x3': 0.8}\n",
      "Intersection of A, B, and C: {'x2': 0.2, 'x1': 0.3, 'x3': 0.3}\n",
      "Complement of A: {'x1': 0.7, 'x2': 0.30000000000000004, 'x3': 0.5}\n",
      "Complement of B: {'x1': 0.4, 'x2': 0.8, 'x3': 0.19999999999999996}\n",
      "Complement of C: {'x1': 0.6, 'x2': 0.09999999999999998, 'x3': 0.7}\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP 12     #####################\n",
    "#Fuzzy set  union, intersection and complement with 3 fuzzy sets\n",
    "# Fuzzy Set Operations\n",
    "def fuzzy_union(A, B):\n",
    "    \"\"\"Return the union of two fuzzy sets A and B.\"\"\"\n",
    "    return {x: max(A.get(x, 0), B.get(x, 0)) for x in set(A) | set(B)}\n",
    "\n",
    "def fuzzy_intersection(A, B):\n",
    "    \"\"\"Return the intersection of two fuzzy sets A and B.\"\"\"\n",
    "    return {x: min(A.get(x, 0), B.get(x, 0)) for x in set(A) | set(B)}\n",
    "\n",
    "def fuzzy_complement(A):\n",
    "    \"\"\"Return the complement of a fuzzy set A.\"\"\"\n",
    "    return {x: 1 - A.get(x, 0) for x in A}\n",
    "\n",
    "# Example fuzzy sets\n",
    "A = {'x1': 0.3, 'x2': 0.7, 'x3': 0.5}\n",
    "B = {'x1': 0.6, 'x2': 0.2, 'x3': 0.8}\n",
    "C = {'x1': 0.4, 'x2': 0.9, 'x3': 0.3}\n",
    "\n",
    "print(\"Fuzzy Set A:\", A)\n",
    "print(\"Fuzzy Set B:\", B)\n",
    "print(\"Fuzzy Set C:\", C)\n",
    "\n",
    "# 1. Union of three fuzzy sets\n",
    "union_AB = fuzzy_union(A, B)\n",
    "union_ABC = fuzzy_union(union_AB, C)\n",
    "\n",
    "# 2. Intersection of three fuzzy sets\n",
    "intersection_AB = fuzzy_intersection(A, B)\n",
    "intersection_ABC = fuzzy_intersection(intersection_AB, C)\n",
    "\n",
    "# 3. Complements of each set\n",
    "complement_A = fuzzy_complement(A)\n",
    "complement_B = fuzzy_complement(B)\n",
    "complement_C = fuzzy_complement(C)\n",
    "\n",
    "print(\"\\nUnion of A, B, and C:\", union_ABC)\n",
    "print(\"Intersection of A, B, and C:\", intersection_ABC)\n",
    "print(\"Complement of A:\", complement_A)\n",
    "print(\"Complement of B:\", complement_B)\n",
    "print(\"Complement of C:\", complement_C)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GuINC7ha0Sig",
    "outputId": "7b7999cf-347a-404e-e273-0ad9dd4d0653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy Set 1:\n",
      "Fuzzy Set:\n",
      "Element: a, Membership: 0.8\n",
      "Element: b, Membership: 0.6\n",
      "Element: c, Membership: 0.9\n",
      "Element: d, Membership: 0.4\n",
      "\n",
      "Fuzzy Set 2:\n",
      "Fuzzy Set:\n",
      "Element: b, Membership: 0.7\n",
      "Element: c, Membership: 0.5\n",
      "Element: d, Membership: 0.8\n",
      "Element: e, Membership: 0.3\n",
      "\n",
      "Union of Fuzzy Set 1 and Fuzzy Set 2:\n",
      "Fuzzy Set:\n",
      "Element: d, Membership: 0.8\n",
      "Element: c, Membership: 0.9\n",
      "Element: e, Membership: 0.3\n",
      "Element: b, Membership: 0.7\n",
      "Element: a, Membership: 0.8\n",
      "\n",
      "Intersection of Fuzzy Set 1 and Fuzzy Set 2:\n",
      "Fuzzy Set:\n",
      "Element: d, Membership: 0.4\n",
      "Element: b, Membership: 0.6\n",
      "Element: c, Membership: 0.5\n",
      "\n",
      "Complement of Fuzzy Set 1:\n",
      "Fuzzy Set:\n",
      "Element: a, Membership: 0.19999999999999996\n",
      "Element: b, Membership: 0.4\n",
      "Element: c, Membership: 0.09999999999999998\n",
      "Element: d, Membership: 0.6\n",
      "\n",
      "Demonstrating De Morgan's Law:\n",
      "Complement of Union of Fuzzy Set 1 and Fuzzy Set 2:\n",
      "Fuzzy Set:\n",
      "Element: d, Membership: 0.19999999999999996\n",
      "Element: c, Membership: 0.09999999999999998\n",
      "Element: e, Membership: 0.7\n",
      "Element: b, Membership: 0.30000000000000004\n",
      "Element: a, Membership: 0.19999999999999996\n",
      "\n",
      "Intersection of Complements of Fuzzy Set 1 and Fuzzy Set 2:\n",
      "Fuzzy Set:\n",
      "Element: d, Membership: 0.19999999999999996\n",
      "Element: b, Membership: 0.30000000000000004\n",
      "Element: c, Membership: 0.09999999999999998\n",
      "\n",
      "De Morgan's Law does not hold.\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP 13     #####################\n",
    "# Fuzzy set De Morgans Law with 2 fuzzy sets.\n",
    "\n",
    "# Fuzzy Set Operations\n",
    "class FuzzySet:\n",
    "    def __init__(self, elements, memberships):\n",
    "        self.elements = elements\n",
    "        self.memberships = memberships\n",
    "\n",
    "    # Union of two fuzzy sets\n",
    "    def union(self, other):\n",
    "        result_elements = list(set(self.elements) | set(other.elements))\n",
    "        result_memberships = {}\n",
    "        for element in result_elements:\n",
    "            membership_self = self.memberships.get(element, 0)\n",
    "            membership_other = other.memberships.get(element, 0)\n",
    "            result_memberships[element] = max(membership_self, membership_other)\n",
    "        return FuzzySet(result_elements, result_memberships)\n",
    "\n",
    "    # Intersection of two fuzzy sets\n",
    "    def intersection(self, other):\n",
    "        result_elements = list(set(self.elements) & set(other.elements))\n",
    "        result_memberships = {}\n",
    "        for element in result_elements:\n",
    "            membership_self = self.memberships.get(element, 0)\n",
    "            membership_other = other.memberships.get(element, 0)\n",
    "            result_memberships[element] = min(membership_self, membership_other)\n",
    "        return FuzzySet(result_elements, result_memberships)\n",
    "\n",
    "    # Complement of the fuzzy set\n",
    "    def complement(self):\n",
    "        result_memberships = {element: 1 - membership for element, membership in self.memberships.items()}\n",
    "        return FuzzySet(self.elements, result_memberships)\n",
    "\n",
    "    # Print the fuzzy set\n",
    "    def print_fuzzy_set(self):\n",
    "        print(\"Fuzzy Set:\")\n",
    "        for element in self.elements:\n",
    "            print(f\"Element: {element}, Membership: {self.memberships.get(element, 0)}\")\n",
    "        print()\n",
    "\n",
    "    # Check for equality within a tolerance range (due to floating point precision)\n",
    "    def is_equal(self, other):\n",
    "        tolerance = 1e-6  # Increased tolerance for floating point comparisons\n",
    "        if self.elements != other.elements:\n",
    "            return False\n",
    "        for element in self.elements:\n",
    "            if abs(self.memberships.get(element, 0) - other.memberships.get(element, 0)) > tolerance:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Fuzzy Set 1\n",
    "    fuzzy_set_1 = FuzzySet([\"a\", \"b\", \"c\", \"d\"], {\"a\": 0.8, \"b\": 0.6, \"c\": 0.9, \"d\": 0.4})\n",
    "\n",
    "    # Fuzzy Set 2\n",
    "    fuzzy_set_2 = FuzzySet([\"b\", \"c\", \"d\", \"e\"], {\"b\": 0.7, \"c\": 0.5, \"d\": 0.8, \"e\": 0.3})\n",
    "\n",
    "    # Perform Union, Intersection, and Complement\n",
    "    print(\"Fuzzy Set 1:\")\n",
    "    fuzzy_set_1.print_fuzzy_set()\n",
    "\n",
    "    print(\"Fuzzy Set 2:\")\n",
    "    fuzzy_set_2.print_fuzzy_set()\n",
    "\n",
    "    # Union of fuzzy_set_1 and fuzzy_set_2\n",
    "    union_set = fuzzy_set_1.union(fuzzy_set_2)\n",
    "    print(\"Union of Fuzzy Set 1 and Fuzzy Set 2:\")\n",
    "    union_set.print_fuzzy_set()\n",
    "\n",
    "    # Intersection of fuzzy_set_1 and fuzzy_set_2\n",
    "    intersection_set = fuzzy_set_1.intersection(fuzzy_set_2)\n",
    "    print(\"Intersection of Fuzzy Set 1 and Fuzzy Set 2:\")\n",
    "    intersection_set.print_fuzzy_set()\n",
    "\n",
    "    # Complement of fuzzy_set_1\n",
    "    complement_set_1 = fuzzy_set_1.complement()\n",
    "    print(\"Complement of Fuzzy Set 1:\")\n",
    "    complement_set_1.print_fuzzy_set()\n",
    "\n",
    "    # Union of all three sets (fuzzy_set_1, fuzzy_set_2, fuzzy_set_3)\n",
    "    complement_union = fuzzy_set_1.union(fuzzy_set_2).complement()\n",
    "    complement_fuzzy_set_1 = fuzzy_set_1.complement()\n",
    "    complement_fuzzy_set_2 = fuzzy_set_2.complement()\n",
    "    intersection_complement = complement_fuzzy_set_1.intersection(complement_fuzzy_set_2)\n",
    "\n",
    "    # Demonstrating De Morgan's Law\n",
    "    print(\"Demonstrating De Morgan's Law:\")\n",
    "    print(\"Complement of Union of Fuzzy Set 1 and Fuzzy Set 2:\")\n",
    "    complement_union.print_fuzzy_set()\n",
    "\n",
    "    print(\"Intersection of Complements of Fuzzy Set 1 and Fuzzy Set 2:\")\n",
    "    intersection_complement.print_fuzzy_set()\n",
    "\n",
    "    # Verify if they are the same\n",
    "    if complement_union.is_equal(intersection_complement):\n",
    "        print(\"De Morgan's Law holds: (A  B)^C = A^C  B^C\")\n",
    "    else:\n",
    "        print(\"De Morgan's Law does not hold.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HGrHViUT3a4o",
    "outputId": "b297e76c-0e38-4b7d-af23-d0f9e8de8528"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy Set A: {'x1': 0.2, 'x2': 0.7, 'x3': 0.5}\n",
      "Fuzzy Set B: {'x1': 0.6, 'x2': 0.4, 'x3': 0.8}\n",
      "\n",
      "Union (A  B): {'x1': 0.6, 'x2': 0.7, 'x3': 0.8}\n",
      "Intersection (A  B): {'x1': 0.2, 'x2': 0.4, 'x3': 0.5}\n",
      "\n",
      "Complement of A: {'x1': 0.8, 'x2': 0.30000000000000004, 'x3': 0.5}\n",
      "Complement of B: {'x1': 0.4, 'x2': 0.6, 'x3': 0.19999999999999996}\n",
      "\n",
      "Complement of Union (A  B)': {'x1': 0.4, 'x2': 0.30000000000000004, 'x3': 0.19999999999999996}\n",
      "Intersection of Complements (A'  B'): {'x1': 0.4, 'x2': 0.30000000000000004, 'x3': 0.19999999999999996}\n",
      "\n",
      "De Morgan's Law Verified: True\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP 13     #####################\n",
    "# Fuzzy set  union, intersection and complement. #Demonstrate De Morgans Law ( Complement of Union)\n",
    "\n",
    "# Define two fuzzy sets A and B\n",
    "A = {'x1': 0.2, 'x2': 0.7, 'x3': 0.5}\n",
    "B = {'x1': 0.6, 'x2': 0.4, 'x3': 0.8}\n",
    "\n",
    "# Fuzzy Union\n",
    "def fuzzy_union(A, B):\n",
    "    return {x: max(A[x], B[x]) for x in A}\n",
    "\n",
    "# Fuzzy Intersection\n",
    "def fuzzy_intersection(A, B):\n",
    "    return {x: min(A[x], B[x]) for x in A}\n",
    "\n",
    "# Fuzzy Complement\n",
    "def fuzzy_complement(A):\n",
    "    return {x: 1 - A[x] for x in A}\n",
    "\n",
    "# Perform operations\n",
    "union_AB = fuzzy_union(A, B)\n",
    "intersection_AB = fuzzy_intersection(A, B)\n",
    "complement_A = fuzzy_complement(A)\n",
    "complement_B = fuzzy_complement(B)\n",
    "\n",
    "# Demonstrate De Morgan's Law\n",
    "complement_union = fuzzy_complement(union_AB)\n",
    "intersection_of_complements = fuzzy_intersection(complement_A, complement_B)\n",
    "\n",
    "# Print Results\n",
    "print(\"Fuzzy Set A:\", A)\n",
    "print(\"Fuzzy Set B:\", B)\n",
    "print(\"\\nUnion (A  B):\", union_AB)\n",
    "print(\"Intersection (A  B):\", intersection_AB)\n",
    "print(\"\\nComplement of A:\", complement_A)\n",
    "print(\"Complement of B:\", complement_B)\n",
    "print(\"\\nComplement of Union (A  B)':\", complement_union)\n",
    "print(\"Intersection of Complements (A'  B'):\", intersection_of_complements)\n",
    "\n",
    "# Check if De Morgan's law holds\n",
    "print(\"\\nDe Morgan's Law Verified:\", complement_union == intersection_of_complements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ms9Y1tP44JZR",
    "outputId": "639290aa-9a5e-456a-8342-4accf4ac7034"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fuzzy Set A: {'x1': 0.3, 'x2': 0.8, 'x3': 0.5}\n",
      "Fuzzy Set B: {'x1': 0.7, 'x2': 0.6, 'x3': 0.4}\n",
      "\n",
      "Intersection of A and B: {'x2': 0.6, 'x1': 0.3, 'x3': 0.4}\n",
      "Complement of A: {'x1': 0.7, 'x2': 0.19999999999999996, 'x3': 0.5}\n",
      "Complement of B: {'x1': 0.30000000000000004, 'x2': 0.4, 'x3': 0.6}\n",
      "\n",
      "Complement of (A intersection B): {'x2': 0.4, 'x1': 0.7, 'x3': 0.6}\n",
      "Union of (complement A and complement B): {'x2': 0.4, 'x1': 0.7, 'x3': 0.6}\n",
      "\n",
      "De Morgan's Law Verified: True\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP 14     #####################\n",
    "\n",
    "# Fuzzy set   union, intersection and complement #De Morgans Law ( Complement of Intersection)\n",
    "\n",
    "\n",
    "# Fuzzy Set Operations: Union, Intersection, Complement\n",
    "def fuzzy_union(A, B):\n",
    "    \"\"\"Return the union of two fuzzy sets A and B.\"\"\"\n",
    "    return {x: max(A.get(x, 0), B.get(x, 0)) for x in set(A) | set(B)}\n",
    "\n",
    "def fuzzy_intersection(A, B):\n",
    "    \"\"\"Return the intersection of two fuzzy sets A and B.\"\"\"\n",
    "    return {x: min(A.get(x, 0), B.get(x, 0)) for x in set(A) | set(B)}\n",
    "\n",
    "def fuzzy_complement(A):\n",
    "    \"\"\"Return the complement of a fuzzy set A.\"\"\"\n",
    "    return {x: 1 - A.get(x, 0) for x in A}\n",
    "\n",
    "# Example fuzzy sets\n",
    "A = {'x1': 0.3, 'x2': 0.8, 'x3': 0.5}\n",
    "B = {'x1': 0.7, 'x2': 0.6, 'x3': 0.4}\n",
    "\n",
    "print(\"Fuzzy Set A:\", A)\n",
    "print(\"Fuzzy Set B:\", B)\n",
    "\n",
    "# Operations\n",
    "intersection_AB = fuzzy_intersection(A, B)\n",
    "complement_A = fuzzy_complement(A)\n",
    "complement_B = fuzzy_complement(B)\n",
    "\n",
    "print(\"\\nIntersection of A and B:\", intersection_AB)\n",
    "print(\"Complement of A:\", complement_A)\n",
    "print(\"Complement of B:\", complement_B)\n",
    "\n",
    "# Demonstrate De Morgan's Law (Complement of Intersection)\n",
    "complement_intersection = fuzzy_complement(intersection_AB)\n",
    "union_complements = fuzzy_union(complement_A, complement_B)\n",
    "\n",
    "print(\"\\nComplement of (A intersection B):\", complement_intersection)\n",
    "print(\"Union of (complement A and complement B):\", union_complements)\n",
    "\n",
    "# Check if De Morgan's Law holds\n",
    "print(\"\\nDe Morgan's Law Verified:\", complement_intersection == union_complements)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nmemTjTMcXm8",
    "outputId": "36d2ac61-84ad-4d47-c68d-fffb8576fa0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are 'O'. Computer is 'X'.\n",
      "Positions are numbered as:\n",
      "| 0 | 1 | 2 |\n",
      "| 3 | 4 | 5 |\n",
      "| 6 | 7 | 8 |\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your move (0-8):  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Board after your move:\n",
      "| O |   |   |\n",
      "|   |   |   |\n",
      "|   |   |   |\n",
      "\n",
      "Board after computer's move:\n",
      "| O |   |   |\n",
      "|   | X |   |\n",
      "|   |   |   |\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your move (0-8):  1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Board after your move:\n",
      "| O | O |   |\n",
      "|   | X |   |\n",
      "|   |   |   |\n",
      "\n",
      "Board after computer's move:\n",
      "| O | O | X |\n",
      "|   | X |   |\n",
      "|   |   |   |\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your move (0-8):  6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Board after your move:\n",
      "| O | O | X |\n",
      "|   | X |   |\n",
      "| O |   |   |\n",
      "\n",
      "Board after computer's move:\n",
      "| O | O | X |\n",
      "| X | X |   |\n",
      "| O |   |   |\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter your move (0-8):  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Board after your move:\n",
      "| O | O | X |\n",
      "| X | X |   |\n",
      "| O | O |   |\n",
      "\n",
      "Board after computer's move:\n",
      "| O | O | X |\n",
      "| X | X | X |\n",
      "| O | O |   |\n",
      "\n",
      "Computer wins!\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP 15     #####################\n",
    "\n",
    "#Tic-Tac-Toe, computer wins or it is a draw.\n",
    "import math\n",
    "\n",
    "# Initialize empty board\n",
    "def create_board():\n",
    "    return [' ' for _ in range(9)]\n",
    "\n",
    "# Display the board\n",
    "def print_board(board):\n",
    "    for row in [board[i*3:(i+1)*3] for i in range(3)]:\n",
    "        print('| ' + ' | '.join(row) + ' |')\n",
    "\n",
    "# Check if someone has won\n",
    "def check_winner(board, player):\n",
    "    win_conditions = [\n",
    "        [0, 1, 2], [3, 4, 5], [6, 7, 8], # Rows\n",
    "        [0, 3, 6], [1, 4, 7], [2, 5, 8], # Columns\n",
    "        [0, 4, 8], [2, 4, 6]             # Diagonals\n",
    "    ]\n",
    "    for condition in win_conditions:\n",
    "        if all(board[i] == player for i in condition):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Check if the board is full (draw)\n",
    "def is_full(board):\n",
    "    return ' ' not in board\n",
    "\n",
    "# Minimax Algorithm\n",
    "def minimax(board, is_maximizing):\n",
    "    if check_winner(board, 'X'):\n",
    "        return 1\n",
    "    if check_winner(board, 'O'):\n",
    "        return -1\n",
    "    if is_full(board):\n",
    "        return 0\n",
    "\n",
    "    if is_maximizing:\n",
    "        best_score = -math.inf\n",
    "        for i in range(9):\n",
    "            if board[i] == ' ':\n",
    "                board[i] = 'X'\n",
    "                score = minimax(board, False)\n",
    "                board[i] = ' '\n",
    "                best_score = max(score, best_score)\n",
    "        return best_score\n",
    "    else:\n",
    "        best_score = math.inf\n",
    "        for i in range(9):\n",
    "            if board[i] == ' ':\n",
    "                board[i] = 'O'\n",
    "                score = minimax(board, True)\n",
    "                board[i] = ' '\n",
    "                best_score = min(score, best_score)\n",
    "        return best_score\n",
    "\n",
    "# Computer move using minimax\n",
    "def computer_move(board):\n",
    "    best_score = -math.inf\n",
    "    move = None\n",
    "    for i in range(9):\n",
    "        if board[i] == ' ':\n",
    "            board[i] = 'X'\n",
    "            score = minimax(board, False)\n",
    "            board[i] = ' '\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                move = i\n",
    "    board[move] = 'X'\n",
    "\n",
    "# Main game loop\n",
    "def play_game():\n",
    "    board = create_board()\n",
    "    print(\"You are 'O'. Computer is 'X'.\")\n",
    "    print(\"Positions are numbered as:\")\n",
    "    print_board([str(i) for i in range(9)])\n",
    "\n",
    "    while True:\n",
    "        # Player move\n",
    "        try:\n",
    "            player_move = int(input(\"\\nEnter your move (0-8): \"))\n",
    "            if board[player_move] != ' ':\n",
    "                print(\"Position already taken! Try again.\")\n",
    "                continue\n",
    "            board[player_move] = 'O'\n",
    "        except (ValueError, IndexError):\n",
    "            print(\"Invalid input. Enter a number between 0 and 8.\")\n",
    "            continue\n",
    "\n",
    "        print(\"\\nBoard after your move:\")\n",
    "        print_board(board)\n",
    "\n",
    "        if check_winner(board, 'O'):\n",
    "            print(\"\\nYou win! (This should not happen )\")\n",
    "            break\n",
    "        if is_full(board):\n",
    "            print(\"\\nIt's a draw!\")\n",
    "            break\n",
    "\n",
    "        # Computer move\n",
    "        computer_move(board)\n",
    "        print(\"\\nBoard after computer's move:\")\n",
    "        print_board(board)\n",
    "\n",
    "        if check_winner(board, 'X'):\n",
    "            print(\"\\nComputer wins!\")\n",
    "            break\n",
    "        if is_full(board):\n",
    "            print(\"\\nIt's a draw!\")\n",
    "            break\n",
    "\n",
    "# Start the game\n",
    "if __name__ == \"__main__\":\n",
    "    play_game()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BC5phsY2dhrz",
    "outputId": "3a7bf71b-d802-4d6b-fad2-25ba13e0f9ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Modified Tic-Tac-Toe!\n",
      "\n",
      "\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (0-8):  0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer's turn...\n",
      "\n",
      "\n",
      "O | X |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (0-8):  4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer's turn...\n",
      "\n",
      "\n",
      "O | X | X\n",
      "---------\n",
      "  | O |  \n",
      "---------\n",
      "  |   |  \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (0-8):  7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computer's turn...\n",
      "\n",
      "\n",
      "O | X | X\n",
      "---------\n",
      "X | O |  \n",
      "---------\n",
      "  | O |  \n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your move (0-8):  8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "O | X | X\n",
      "---------\n",
      "X | O |  \n",
      "---------\n",
      "  | O | O\n",
      "You win!\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP 16    #####################\n",
    "\n",
    "#Tic-Tac-Toe computer loses or it is a draw.\n",
    "\n",
    "import math\n",
    "\n",
    "# Print the board\n",
    "def print_board(board):\n",
    "    print(\"\\n\")\n",
    "    for i in range(0, 9, 3):\n",
    "        print(\" | \".join(board[i:i+3]))\n",
    "        if i < 6:\n",
    "            print(\"---------\")\n",
    "\n",
    "# Check for a winner\n",
    "def check_winner(board, player):\n",
    "    win_conditions = [\n",
    "        [0, 1, 2], [3, 4, 5], [6, 7, 8],  # Rows\n",
    "        [0, 3, 6], [1, 4, 7], [2, 5, 8],  # Columns\n",
    "        [0, 4, 8], [2, 4, 6]              # Diagonals\n",
    "    ]\n",
    "    for condition in win_conditions:\n",
    "        if all(board[i] == player for i in condition):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Check if the board is full\n",
    "def is_full(board):\n",
    "    return ' ' not in board\n",
    "\n",
    "# Minimax function\n",
    "def minimax(board, is_maximizing, depth=0):\n",
    "    if check_winner(board, 'X'):  # Computer wins\n",
    "        return 1  # Return 1 to represent a loss for the computer\n",
    "    if check_winner(board, 'O'):  # Player wins\n",
    "        return -1  # Return -1 to represent a win for the player\n",
    "    if is_full(board):            # Draw\n",
    "        return 0\n",
    "\n",
    "    if is_maximizing:  # Computer's turn (maximizing)\n",
    "        best_score = math.inf  # Minimize score (computer prefers losing)\n",
    "        for i in range(9):\n",
    "            if board[i] == ' ':\n",
    "                board[i] = 'X'  # Make move\n",
    "                score = minimax(board, False, depth + 1)  # Minimize players best move\n",
    "                board[i] = ' '  # Undo move\n",
    "                best_score = min(score, best_score)  # Minimize computer's score\n",
    "        return best_score\n",
    "    else:  # Player's turn (minimizing)\n",
    "        best_score = -math.inf  # Maximize score (player wants to win)\n",
    "        for i in range(9):\n",
    "            if board[i] == ' ':\n",
    "                board[i] = 'O'  # Make move\n",
    "                score = minimax(board, True, depth + 1)  # Maximize computers worst move\n",
    "                board[i] = ' '  # Undo move\n",
    "                best_score = max(score, best_score)  # Maximize players score\n",
    "        return best_score\n",
    "\n",
    "# Computer makes a move using minimax\n",
    "def computer_move(board):\n",
    "    best_score = math.inf\n",
    "    move = None\n",
    "    for i in range(9):\n",
    "        if board[i] == ' ':\n",
    "            board[i] = 'X'\n",
    "            score = minimax(board, False)  # Minimize player's score\n",
    "            board[i] = ' '  # Undo move\n",
    "            if score < best_score:\n",
    "                best_score = score\n",
    "                move = i\n",
    "    board[move] = 'X'\n",
    "    return move\n",
    "\n",
    "# Main game function\n",
    "def play_game():\n",
    "    board = [' ' for _ in range(9)]  # Initial empty board\n",
    "    print(\"Welcome to Modified Tic-Tac-Toe!\")\n",
    "\n",
    "    while True:\n",
    "        print_board(board)\n",
    "\n",
    "        # Player's turn\n",
    "        while True:\n",
    "            try:\n",
    "                move = int(input(\"Enter your move (0-8): \"))\n",
    "                if move < 0 or move > 8 or board[move] != ' ':\n",
    "                    print(\"Invalid move, try again.\")\n",
    "                    continue\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"Invalid input, please enter a number between 0 and 8.\")\n",
    "\n",
    "        board[move] = 'O'\n",
    "\n",
    "        if check_winner(board, 'O'):\n",
    "            print_board(board)\n",
    "            print(\"You win!\")\n",
    "            break\n",
    "        if is_full(board):\n",
    "            print_board(board)\n",
    "            print(\"It's a draw!\")\n",
    "            break\n",
    "\n",
    "        # Computer's turn\n",
    "        print(\"Computer's turn...\")\n",
    "        computer_move(board)\n",
    "\n",
    "        if check_winner(board, 'X'):\n",
    "            print_board(board)\n",
    "            print(\"Computer wins! (Shouldn't happen in this version!)\")\n",
    "            break\n",
    "        if is_full(board):\n",
    "            print_board(board)\n",
    "            print(\"It's a draw!\")\n",
    "            break\n",
    "\n",
    "# Start the game\n",
    "if __name__ == \"__main__\":\n",
    "    play_game()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MmcLIA9_2RIe",
    "outputId": "23ac29e4-796f-4032-c0a7-facd8de6928e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1:\n",
      "Input: [1 0]\n",
      "Hidden Layer 1 Output: [1 1 0 0]\n",
      "Hidden Layer 2 Output: [1 1 0]\n",
      "Final Output: [1]\n",
      "Weights1:\n",
      " [[ 0.12517568  0.93299722 -0.0090305  -0.29298171]\n",
      " [ 1.21664946 -1.63212866  0.19919425 -0.20909216]]\n",
      "Bias1:\n",
      " [-0.03889825  0.17850166 -0.61905156 -1.13167942]\n",
      "Weights2:\n",
      " [[ 0.91838908 -0.57363036  0.21036175]\n",
      " [ 2.91563655  1.23320344 -0.58376811]\n",
      " [ 0.32719081 -0.75025462 -0.98871684]\n",
      " [ 0.82079487 -0.16543652  0.48499669]]\n",
      "Bias2:\n",
      " [ 0.21120545 -0.30173658 -1.85431477]\n",
      "Weights3:\n",
      " [[0.60072783]\n",
      " [0.49591716]\n",
      " [0.22936769]]\n",
      "Bias3:\n",
      " [-0.47288837]\n",
      "\n",
      "Step 2:\n",
      "Input: [1 0]\n",
      "Hidden Layer 1 Output: [0 1 1 1]\n",
      "Hidden Layer 2 Output: [1 1 1]\n",
      "Final Output: [1]\n",
      "Weights1:\n",
      " [[-1.3714115  -0.10692896  0.77423555  0.57810111]\n",
      " [ 0.05381681  0.15200436 -0.57373752 -0.52182959]]\n",
      "Bias1:\n",
      " [0.57586629 0.58758681 0.60879798 0.10620693]\n",
      "Weights2:\n",
      " [[-1.14330598  1.28628398 -0.74511521]\n",
      " [ 0.37573271  0.3586884   1.62169834]\n",
      " [-0.00335369 -1.01252171  1.09317826]\n",
      " [ 1.16592447 -0.21741154  0.67222342]]\n",
      "Bias2:\n",
      " [-0.78152399  1.35580767  1.1437859 ]\n",
      "Weights3:\n",
      " [[-0.4015583 ]\n",
      " [ 2.75120902]\n",
      " [ 0.41581967]]\n",
      "Bias3:\n",
      " [0.46117925]\n",
      "\n",
      "Step 3:\n",
      "Input: [1 0]\n",
      "Hidden Layer 1 Output: [1 1 1 1]\n",
      "Hidden Layer 2 Output: [1 0 1]\n",
      "Final Output: [1]\n",
      "Weights1:\n",
      " [[-0.09871847  0.98635902  0.48554918  1.51434618]\n",
      " [-0.57761105  0.30144638  0.05562796  1.03470088]]\n",
      "Bias1:\n",
      " [ 1.50088654 -0.13354352  0.42571318  1.42471493]\n",
      "Weights2:\n",
      " [[ 0.72199466 -0.83514896 -0.5473973 ]\n",
      " [-0.07671321  0.46847483  0.30499921]\n",
      " [-0.40741465  0.74223714  0.71912591]\n",
      " [-0.47089725 -1.42378716  1.56692553]]\n",
      "Bias2:\n",
      " [ 2.08776422 -0.64410207 -0.4061407 ]\n",
      "Weights3:\n",
      " [[ 1.22018016]\n",
      " [-0.26753108]\n",
      " [ 0.09705557]]\n",
      "Bias3:\n",
      " [-1.11562774]\n",
      "\n",
      "Total Steps Performed: 3\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP 17    #####################\n",
    "\n",
    "# MLP with N binary inputs, two hidden layers and one binary output\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Activation function (binary step function)\n",
    "def binary_step(x):\n",
    "    return np.where(x >= 0, 1, 0)\n",
    "\n",
    "# Forward pass through the network\n",
    "def forward_pass(x, weights1, bias1, weights2, bias2, weights3, bias3):\n",
    "    hidden1 = binary_step(np.dot(x, weights1) + bias1)\n",
    "    hidden2 = binary_step(np.dot(hidden1, weights2) + bias2)\n",
    "    output = binary_step(np.dot(hidden2, weights3) + bias3)\n",
    "    return output, hidden1, hidden2\n",
    "\n",
    "# Input vector (example)\n",
    "x = np.array([1, 0])  # you can make it general for N inputs\n",
    "\n",
    "# Number of steps you want to perform\n",
    "steps = 3  # you can change this as needed\n",
    "\n",
    "for step in range(1, steps + 1):\n",
    "    # Randomly initialize weights and biases in every iteration\n",
    "    weights1 = np.random.randn(2, 4)   # input layer -> first hidden layer\n",
    "    bias1 = np.random.randn(4)\n",
    "\n",
    "    weights2 = np.random.randn(4, 3)   # first hidden layer -> second hidden layer\n",
    "    bias2 = np.random.randn(3)\n",
    "\n",
    "    weights3 = np.random.randn(3, 1)   # second hidden layer -> output layer\n",
    "    bias3 = np.random.randn(1)\n",
    "\n",
    "    # Perform forward pass\n",
    "    output, hidden1, hidden2 = forward_pass(x, weights1, bias1, weights2, bias2, weights3, bias3)\n",
    "\n",
    "    # Display output at each step\n",
    "    print(f\"\\nStep {step}:\")\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Hidden Layer 1 Output:\", hidden1)\n",
    "    print(\"Hidden Layer 2 Output:\", hidden2)\n",
    "    print(\"Final Output:\", output)\n",
    "    print(\"Weights1:\\n\", weights1)\n",
    "    print(\"Bias1:\\n\", bias1)\n",
    "    print(\"Weights2:\\n\", weights2)\n",
    "    print(\"Bias2:\\n\", bias2)\n",
    "    print(\"Weights3:\\n\", weights3)\n",
    "    print(\"Bias3:\\n\", bias3)\n",
    "\n",
    "print(f\"\\nTotal Steps Performed: {steps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbNkqqPX3lyF",
    "outputId": "3d38c0e3-1236-4899-99f3-c50a4926291e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1:\n",
      "Input: [0 0 0 0]\n",
      "Hidden Layer Output: [1 0 0]\n",
      "Final Output (2 values): [0 0]\n",
      "Weights1 (Input to Hidden):\n",
      " [[ 0.37028709 -0.46109229  2.03682964]\n",
      " [ 1.26595692 -0.41284316  0.96465981]\n",
      " [-0.1387365  -0.81163815 -0.57758503]\n",
      " [ 0.98070557  0.70074684  1.75853437]]\n",
      "Bias1:\n",
      " [ 1.69779598 -0.9561313  -0.5550677 ]\n",
      "Weights2 (Hidden to Output):\n",
      " [[-0.54197438  0.2569238 ]\n",
      " [-1.79415706 -1.5614437 ]\n",
      " [ 2.73965304 -0.95990004]]\n",
      "Bias2:\n",
      " [-0.08678637 -0.56042629]\n",
      "\n",
      "Step 2:\n",
      "Input: [0 0 0 0]\n",
      "Hidden Layer Output: [0 0 1]\n",
      "Final Output (2 values): [0 1]\n",
      "Weights1 (Input to Hidden):\n",
      " [[-0.42006199  0.23755611 -0.54630597]\n",
      " [-0.79632746  0.92377317  0.20535063]\n",
      " [-0.48093404  0.81326676  0.05160565]\n",
      " [ 0.43752385 -0.87578839  1.70881754]]\n",
      "Bias1:\n",
      " [-1.46061616 -1.74331418  0.28048463]\n",
      "Weights2 (Hidden to Output):\n",
      " [[-1.75081729 -0.00855364]\n",
      " [-1.4079037   0.06143026]\n",
      " [-0.63449128  1.54064779]]\n",
      "Bias2:\n",
      " [0.3520812  1.34844653]\n",
      "\n",
      "Step 3:\n",
      "Input: [0 0 0 0]\n",
      "Hidden Layer Output: [1 1 1]\n",
      "Final Output (2 values): [1 1]\n",
      "Weights1 (Input to Hidden):\n",
      " [[ 0.81774068 -0.47107362  0.09686263]\n",
      " [-2.08405849  0.86700833 -1.25293803]\n",
      " [ 0.75096023 -0.39163594  1.21555658]\n",
      " [-0.00379901  0.57982253  1.242064  ]]\n",
      "Bias1:\n",
      " [0.71103643 1.56526397 0.0033611 ]\n",
      "Weights2 (Hidden to Output):\n",
      " [[ 0.54381804  2.43320992]\n",
      " [ 0.40668     0.09488743]\n",
      " [-0.60889828 -0.1922563 ]]\n",
      "Bias2:\n",
      " [1.29344863 0.79999225]\n",
      "\n",
      "Total Steps Performed: 3\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP 18    #####################\n",
    "\n",
    "# MLP with 4 binary inputs, one hidden layer and two binary outputs\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Activation function (binary step function)\n",
    "def binary_step(x):\n",
    "    return np.where(x >= 0, 1, 0)\n",
    "\n",
    "# Forward pass through the network\n",
    "def forward_pass(x, weights1, bias1, weights2, bias2):\n",
    "    hidden = binary_step(np.dot(x, weights1) + bias1)\n",
    "    output = binary_step(np.dot(hidden, weights2) + bias2)\n",
    "    return output, hidden\n",
    "\n",
    "# Number of inputs\n",
    "input_size = 4\n",
    "\n",
    "# Number of neurons\n",
    "hidden_layer_size = 3  # You can change if needed\n",
    "output_size = 2\n",
    "\n",
    "# Example input vector (4 binary inputs)\n",
    "x = np.random.randint(0, 2, size=(input_size,))\n",
    "\n",
    "# Number of steps you want to perform\n",
    "steps = 3\n",
    "\n",
    "for step in range(1, steps + 1):\n",
    "    # Randomly initialize weights and biases\n",
    "    weights1 = np.random.randn(input_size, hidden_layer_size)   # input -> hidden layer\n",
    "    bias1 = np.random.randn(hidden_layer_size)\n",
    "\n",
    "    weights2 = np.random.randn(hidden_layer_size, output_size)  # hidden layer -> output layer\n",
    "    bias2 = np.random.randn(output_size)\n",
    "\n",
    "    # Perform forward pass\n",
    "    output, hidden = forward_pass(x, weights1, bias1, weights2, bias2)\n",
    "\n",
    "    # Display outputs at each step\n",
    "    print(f\"\\nStep {step}:\")\n",
    "    print(\"Input:\", x)\n",
    "    print(\"Hidden Layer Output:\", hidden)\n",
    "    print(\"Final Output (2 values):\", output)\n",
    "    print(\"Weights1 (Input to Hidden):\\n\", weights1)\n",
    "    print(\"Bias1:\\n\", bias1)\n",
    "    print(\"Weights2 (Hidden to Output):\\n\", weights2)\n",
    "    print(\"Bias2:\\n\", bias2)\n",
    "\n",
    "print(f\"\\nTotal Steps Performed: {steps}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W0Ct31Cf94UL",
    "outputId": "9caee75f-8df0-4aaf-efe9-f58d06fb55c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.6628\n",
      "Epoch 1000, Loss: 0.1945\n",
      "Epoch 2000, Loss: 0.0625\n",
      "Epoch 3000, Loss: 0.0416\n",
      "Epoch 4000, Loss: 0.0327\n",
      "Epoch 5000, Loss: 0.0276\n",
      "Epoch 6000, Loss: 0.0242\n",
      "Epoch 7000, Loss: 0.0218\n",
      "Epoch 8000, Loss: 0.0200\n",
      "Epoch 9000, Loss: 0.0185\n",
      "Training complete.\n",
      "\n",
      "Predictions:\n",
      "[[0.0137044 ]\n",
      " [0.98262792]\n",
      " [0.98218135]\n",
      " [0.01964019]]\n",
      "\n",
      "Final weights and biases:\n",
      "w1:\n",
      " [[ 1.70512818 -0.83143756 -1.46424312 -2.4632222 ]\n",
      " [ 1.75696713 -0.06068882 -2.29376658 -2.65313089]\n",
      " [-2.60535968  1.2284938  -2.69553471  3.81409117]]\n",
      "b1:\n",
      " [[ 0.16845649 -0.32851521  0.97433812 -0.11202258]]\n",
      "w2:\n",
      " [[-2.2558105  -0.38252041  3.13431951]\n",
      " [ 0.55220984 -0.68347492 -0.84906996]\n",
      " [-1.72233968 -0.31065308  3.24172348]\n",
      " [ 3.35621061 -0.68747181 -4.32781832]]\n",
      "b2:\n",
      " [[-0.55932586  0.00118328  0.61894721]]\n",
      "w3:\n",
      " [[ 4.99666441]\n",
      " [-0.16101538]\n",
      " [-6.73382359]]\n",
      "b3:\n",
      " [[0.72918497]]\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP 19    #####################\n",
    "\n",
    "# MLP with N binary inputs, two hidden layers and one output. Use backpropagation and Sigmoid function\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"Implement a simple Multi-Layer Perceptron with N binary inputs, two\n",
    "hidden layers and one output. Use backpropagation and Sigmoid function\n",
    "as activation function. \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Sigmoid and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    sx = sigmoid(x)\n",
    "    return sx * (1 - sx)\n",
    "\n",
    "# Binary Cross-Entropy Loss\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    return -np.mean(y_true*np.log(y_pred+1e-8) + (1 - y_true)*np.log(1 - y_pred + 1e-8))\n",
    "\n",
    "# MLP class\n",
    "class MLP:\n",
    "    def __init__(self, input_size, hidden1_size, hidden2_size, learning_rate=0.1):\n",
    "        self.lr = learning_rate\n",
    "\n",
    "        self.w1 = np.random.randn(input_size, hidden1_size)\n",
    "        self.b1 = np.zeros((1, hidden1_size))\n",
    "\n",
    "        self.w2 = np.random.randn(hidden1_size, hidden2_size)\n",
    "        self.b2 = np.zeros((1, hidden2_size))\n",
    "\n",
    "        self.w3 = np.random.randn(hidden2_size, 1)\n",
    "        self.b3 = np.zeros((1, 1))\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.w1) + self.b1\n",
    "        self.a1 = sigmoid(self.z1)\n",
    "\n",
    "        self.z2 = np.dot(self.a1, self.w2) + self.b2\n",
    "        self.a2 = sigmoid(self.z2)\n",
    "\n",
    "        self.z3 = np.dot(self.a2, self.w3) + self.b3\n",
    "        self.a3 = sigmoid(self.z3)\n",
    "\n",
    "        return self.a3\n",
    "\n",
    "    def backward(self, X, y, output):\n",
    "        m = X.shape[0]\n",
    "        error = output - y\n",
    "\n",
    "        dz3 = error * sigmoid_derivative(self.z3)\n",
    "        dw3 = np.dot(self.a2.T, dz3) / m\n",
    "        db3 = np.sum(dz3, axis=0, keepdims=True) / m\n",
    "\n",
    "        dz2 = np.dot(dz3, self.w3.T) * sigmoid_derivative(self.z2)\n",
    "        dw2 = np.dot(self.a1.T, dz2) / m\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
    "\n",
    "        dz1 = np.dot(dz2, self.w2.T) * sigmoid_derivative(self.z1)\n",
    "        dw1 = np.dot(X.T, dz1) / m\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
    "\n",
    "        # Update weights\n",
    "        self.w3 -= self.lr * dw3\n",
    "        self.b3 -= self.lr * db3\n",
    "\n",
    "        self.w2 -= self.lr * dw2\n",
    "        self.b2 -= self.lr * db2\n",
    "\n",
    "        self.w1 -= self.lr * dw1\n",
    "        self.b1 -= self.lr * db1\n",
    "\n",
    "    def train(self, X, y, epochs=10000, verbose=False):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            loss = binary_cross_entropy(y, output)\n",
    "            self.backward(X, y, output)\n",
    "            if verbose and epoch % 1000 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "        print(\"Training complete.\")\n",
    "\n",
    "# Sample binary input data (N = 3)\n",
    "X = np.array([\n",
    "    [0, 0, 0],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1],\n",
    "    [1, 1, 1]\n",
    "])\n",
    "\n",
    "y = np.array([[0], [1], [1], [0]])  # XOR-like output\n",
    "\n",
    "# Create and train model\n",
    "mlp = MLP(input_size=3, hidden1_size=4, hidden2_size=3, learning_rate=0.5)\n",
    "mlp.train(X, y, epochs=10000, verbose=True)\n",
    "\n",
    "# Final outputs\n",
    "print(\"\\nPredictions:\")\n",
    "print(mlp.forward(X))\n",
    "\n",
    "print(\"\\nFinal weights and biases:\")\n",
    "print(\"w1:\\n\", mlp.w1)\n",
    "print(\"b1:\\n\", mlp.b1)\n",
    "print(\"w2:\\n\", mlp.w2)\n",
    "print(\"b2:\\n\", mlp.b2)\n",
    "print(\"w3:\\n\", mlp.w3)\n",
    "print(\"b3:\\n\", mlp.b3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ng4YOQA8-tV8",
    "outputId": "055fe544-1715-4a11-bafa-3cddd8f9ffa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7112\n",
      "Epoch 1000, Loss: 0.0788\n",
      "Epoch 2000, Loss: 0.0418\n",
      "Epoch 3000, Loss: 0.0303\n",
      "Epoch 4000, Loss: 0.0244\n",
      "Epoch 5000, Loss: 0.0208\n",
      "Epoch 6000, Loss: 0.0183\n",
      "Epoch 7000, Loss: 0.0165\n",
      "Epoch 8000, Loss: 0.0151\n",
      "Epoch 9000, Loss: 0.0139\n",
      "Training complete.\n",
      "\n",
      "Predictions after training:\n",
      "[[0.02 ]\n",
      " [0.991]\n",
      " [0.991]\n",
      " [0.014]]\n",
      "\n",
      "Final weights and biases:\n",
      "w1:\n",
      " [[-1.08967692e+00  4.30896771e-01  9.36378972e-01 -1.35744819e+00\n",
      "  -1.55013344e+00]\n",
      " [-5.97390517e-04 -5.03919126e-01  4.87130106e-01 -1.25751813e+00\n",
      "  -7.32003032e-02]\n",
      " [-1.22386323e+00  9.95202770e-01 -1.51825211e+00  2.50296632e+00\n",
      "  -4.76409576e-01]]\n",
      "b1:\n",
      " [[ 0.         -0.10572034  0.          0.1119991   0.        ]]\n",
      "w2:\n",
      " [[-0.35771118  0.03676079  1.47527073]\n",
      " [ 0.63369116  1.30126904  0.33158004]\n",
      " [ 0.01857126  0.65931953  1.63549501]\n",
      " [-0.53626304  1.36642625  2.41686556]\n",
      " [-0.74910746 -1.26853296  0.69701592]]\n",
      "b2:\n",
      " [[ 1.39996748 -0.26982119 -0.27072922]]\n",
      "w3:\n",
      " [[-1.65931089]\n",
      " [ 0.81789325]\n",
      " [ 1.99259392]]\n",
      "b3:\n",
      " [[-1.69335361]]\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP 20    #####################\n",
    "\n",
    "# MLP with N binary inputs, two hidden layers and one output. Use backpropagation and ReLU function as activation function.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# ReLU activation function and its derivative\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "# Sigmoid activation function and its derivative (used in the output layer)\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "# Binary Cross-Entropy Loss function\n",
    "def binary_cross_entropy(y_true, y_pred):\n",
    "    return -np.mean(y_true * np.log(y_pred + 1e-8) + (1 - y_true) * np.log(1 - y_pred + 1e-8))\n",
    "\n",
    "# MLP class with forward and backward propagation\n",
    "class MLP:\n",
    "    def __init__(self, input_size, hidden1_size, hidden2_size, learning_rate=0.1):\n",
    "        self.lr = learning_rate\n",
    "        self.w1 = np.random.randn(input_size, hidden1_size)\n",
    "        self.b1 = np.zeros((1, hidden1_size))\n",
    "\n",
    "        self.w2 = np.random.randn(hidden1_size, hidden2_size)\n",
    "        self.b2 = np.zeros((1, hidden2_size))\n",
    "\n",
    "        self.w3 = np.random.randn(hidden2_size, 1)\n",
    "        self.b3 = np.zeros((1, 1))\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Forward pass: input -> hidden1 -> hidden2 -> output\n",
    "        self.z1 = np.dot(X, self.w1) + self.b1\n",
    "        self.a1 = relu(self.z1)\n",
    "\n",
    "        self.z2 = np.dot(self.a1, self.w2) + self.b2\n",
    "        self.a2 = relu(self.z2)\n",
    "\n",
    "        self.z3 = np.dot(self.a2, self.w3) + self.b3\n",
    "        self.a3 = sigmoid(self.z3)  # Output layer\n",
    "        return self.a3\n",
    "\n",
    "    def backward(self, X, y, output):\n",
    "        m = X.shape[0]\n",
    "\n",
    "        # Calculate the error\n",
    "        error = output - y\n",
    "\n",
    "        # Backpropagation step by step\n",
    "        dz3 = error * sigmoid_derivative(self.z3)\n",
    "        dw3 = np.dot(self.a2.T, dz3) / m\n",
    "        db3 = np.sum(dz3, axis=0, keepdims=True) / m\n",
    "\n",
    "        dz2 = np.dot(dz3, self.w3.T) * relu_derivative(self.z2)\n",
    "        dw2 = np.dot(self.a1.T, dz2) / m\n",
    "        db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
    "\n",
    "        dz1 = np.dot(dz2, self.w2.T) * relu_derivative(self.z1)\n",
    "        dw1 = np.dot(X.T, dz1) / m\n",
    "        db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
    "\n",
    "        # Update the weights and biases using gradient descent\n",
    "        self.w3 -= self.lr * dw3\n",
    "        self.b3 -= self.lr * db3\n",
    "\n",
    "        self.w2 -= self.lr * dw2\n",
    "        self.b2 -= self.lr * db2\n",
    "\n",
    "        self.w1 -= self.lr * dw1\n",
    "        self.b1 -= self.lr * db1\n",
    "\n",
    "    def train(self, X, y, epochs=10000, verbose=False):\n",
    "        for epoch in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            loss = binary_cross_entropy(y, output)\n",
    "            self.backward(X, y, output)\n",
    "            if verbose and epoch % 1000 == 0:\n",
    "                print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "        print(\"Training complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample data: XOR-like problem with 3 binary inputs\n",
    "    X = np.array([\n",
    "        [0, 0, 0],\n",
    "        [0, 1, 1],\n",
    "        [1, 0, 1],\n",
    "        [1, 1, 1],\n",
    "    ])\n",
    "\n",
    "    # Target values for XOR problem\n",
    "    y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "    # Create and train the MLP model\n",
    "    mlp = MLP(input_size=3, hidden1_size=5, hidden2_size=3, learning_rate=0.1)\n",
    "    mlp.train(X, y, epochs=10000, verbose=True)\n",
    "\n",
    "    # Show predictions after training\n",
    "    print(\"\\nPredictions after training:\")\n",
    "    predictions = np.round(mlp.forward(X), 3)\n",
    "    print(predictions)\n",
    "\n",
    "    # Display final weights and biases\n",
    "    print(\"\\nFinal weights and biases:\")\n",
    "    print(\"w1:\\n\", mlp.w1)\n",
    "    print(\"b1:\\n\", mlp.b1)\n",
    "    print(\"w2:\\n\", mlp.w2)\n",
    "    print(\"b2:\\n\", mlp.b2)\n",
    "    print(\"w3:\\n\", mlp.w3)\n",
    "    print(\"b3:\\n\", mlp.b3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9KvXnN-6AkFs",
    "outputId": "644a2d9e-0f34-4fb7-a198-53d13229bab9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.2426\n",
      "Epoch 1000, Loss: 0.0000\n",
      "Epoch 2000, Loss: 0.0000\n",
      "Epoch 3000, Loss: 0.0000\n",
      "Epoch 4000, Loss: 0.0000\n",
      "Epoch 5000, Loss: 0.0000\n",
      "Epoch 6000, Loss: 0.0000\n",
      "Epoch 7000, Loss: 0.0000\n",
      "Epoch 8000, Loss: 0.0000\n",
      "Epoch 9000, Loss: 0.0000\n",
      "Training complete.\n",
      "\n",
      "Predictions after training:\n",
      "[[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n",
      "\n",
      "Final weights and biases:\n",
      "w1:\n",
      " [[ 0.67214665  2.34042569 -0.26611944  1.28505524]\n",
      " [ 0.7430681  -0.21131517 -0.71262621  1.16174958]]\n",
      "b1:\n",
      " [[0.24503122 0.24503122 0.24503122 0.24503122]]\n",
      "w2:\n",
      " [[-0.4868978  -0.7448623  -0.59238286]\n",
      " [ 0.68077265  0.57208819 -0.59604135]\n",
      " [-1.44370287 -1.45054295  0.34627394]\n",
      " [-1.04290617  1.47424445 -1.49939806]]\n",
      "b2:\n",
      " [[0.41939155 0.41939155 0.41939155]]\n",
      "w3:\n",
      " [[-1.58743962]\n",
      " [-0.14606547]\n",
      " [-1.23304703]]\n",
      "b3:\n",
      " [[-0.329308]]\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP 21    #####################\n",
    "\n",
    "# MLP with with N binary inputs, two hidden layers and one output. Use backpropagation and Tanh function as activation function.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Tanh and its derivative\n",
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "\n",
    "def tanh_derivative(x):\n",
    "    return 1.0 - np.tanh(x)**2\n",
    "\n",
    "# MLP class with backpropagation and Tanh activation\n",
    "class MLP:\n",
    "    def __init__(self, input_size, hidden1_size, hidden2_size):\n",
    "        # Randomly initialize weights and biases\n",
    "        self.w1 = np.random.randn(input_size, hidden1_size)  # Weights for first layer\n",
    "        self.b1 = np.zeros((1, hidden1_size))  # Bias for first layer\n",
    "\n",
    "        self.w2 = np.random.randn(hidden1_size, hidden2_size)  # Weights for second layer\n",
    "        self.b2 = np.zeros((1, hidden2_size))  # Bias for second layer\n",
    "\n",
    "        self.w3 = np.random.randn(hidden2_size, 1)  # Weights for output layer\n",
    "        self.b3 = np.zeros((1, 1))  # Bias for output layer\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Forward pass (compute activations for each layer)\n",
    "        self.z1 = np.dot(X, self.w1) + self.b1\n",
    "        self.a1 = tanh(self.z1)\n",
    "\n",
    "        self.z2 = np.dot(self.a1, self.w2) + self.b2\n",
    "        self.a2 = tanh(self.z2)\n",
    "\n",
    "        self.z3 = np.dot(self.a2, self.w3) + self.b3\n",
    "        self.a3 = self.z3  # No activation on the output layer for binary classification (regression output)\n",
    "        return self.a3\n",
    "\n",
    "    def backprop(self, X, y, learning_rate):\n",
    "        # Backpropagation (gradient descent)\n",
    "        m = X.shape[0]  # Number of examples\n",
    "\n",
    "        # Output layer error\n",
    "        error_output = self.a3 - y\n",
    "        d_w3 = np.dot(self.a2.T, error_output) / m\n",
    "        d_b3 = np.sum(error_output) / m\n",
    "\n",
    "        # Second hidden layer error\n",
    "        error_hidden2 = np.dot(error_output, self.w3.T) * tanh_derivative(self.z2)\n",
    "        d_w2 = np.dot(self.a1.T, error_hidden2) / m\n",
    "        d_b2 = np.sum(error_hidden2) / m\n",
    "\n",
    "        # First hidden layer error\n",
    "        error_hidden1 = np.dot(error_hidden2, self.w2.T) * tanh_derivative(self.z1)\n",
    "        d_w1 = np.dot(X.T, error_hidden1) / m\n",
    "        d_b1 = np.sum(error_hidden1) / m\n",
    "\n",
    "        # Update weights and biases\n",
    "        self.w1 -= learning_rate * d_w1\n",
    "        self.b1 -= learning_rate * d_b1\n",
    "        self.w2 -= learning_rate * d_w2\n",
    "        self.b2 -= learning_rate * d_b2\n",
    "        self.w3 -= learning_rate * d_w3\n",
    "        self.b3 -= learning_rate * d_b3\n",
    "\n",
    "    def train(self, X, y, epochs, learning_rate):\n",
    "        # Training loop with backpropagation\n",
    "        for epoch in range(epochs):\n",
    "            self.forward(X)\n",
    "            self.backprop(X, y, learning_rate)\n",
    "\n",
    "            if epoch % 1000 == 0:\n",
    "                loss = np.mean((self.a3 - y)**2)\n",
    "                print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "        print(\"Training complete.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Sample XOR-like input (with binary inputs)\n",
    "    X = np.array([\n",
    "        [0, 0],\n",
    "        [0, 1],\n",
    "        [1, 0],\n",
    "        [1, 1],\n",
    "    ])\n",
    "\n",
    "    # Expected output (binary classification for XOR)\n",
    "    y = np.array([\n",
    "        [0],\n",
    "        [1],\n",
    "        [1],\n",
    "        [0],\n",
    "    ])\n",
    "\n",
    "    # Create the model\n",
    "    input_size = X.shape[1]  # Number of input features (N binary inputs)\n",
    "    hidden1_size = 4         # Number of neurons in the first hidden layer\n",
    "    hidden2_size = 3         # Number of neurons in the second hidden layer\n",
    "\n",
    "    mlp = MLP(input_size, hidden1_size, hidden2_size)\n",
    "\n",
    "    # Train the model\n",
    "    epochs = 10000\n",
    "    learning_rate = 0.1\n",
    "    mlp.train(X, y, epochs, learning_rate)\n",
    "\n",
    "    # Predictions after training\n",
    "    predictions = mlp.forward(X)\n",
    "    print(\"\\nPredictions after training:\")\n",
    "    print(np.round(predictions, 3))\n",
    "\n",
    "    # Final weights and biases\n",
    "    print(\"\\nFinal weights and biases:\")\n",
    "    print(\"w1:\\n\", mlp.w1)\n",
    "    print(\"b1:\\n\", mlp.b1)\n",
    "    print(\"w2:\\n\", mlp.w2)\n",
    "    print(\"b2:\\n\", mlp.b2)\n",
    "    print(\"w3:\\n\", mlp.w3)\n",
    "    print(\"b3:\\n\", mlp.b3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "of6O-VXbBSQ3",
    "outputId": "06d58436-4015-4359-a34b-d82e229059fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in c:\\users\\shank\\anaconda3\\lib\\site-packages (0.8.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shank\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\shank\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shank\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Tokens:\n",
      " ['artificial', 'intelligence', 'is', 'rapidly', 'changing', 'the', 'world', 'every', 'day', 'new', 'advancements', 'are', 'made', 'in', 'machine', 'learning', 'and', 'deep', 'learning', 'these', 'technologies', 'are', 'helping', 'businesses', 'make', 'smarter', 'decisions', 'they', 'are', 'also', 'improving', 'healthcare', 'education', 'and', 'entertainment', 'industries', 'however', 'with', 'great', 'power', 'comes', 'great', 'responsibility', 'ethical', 'concerns', 'around', 'ai', 'are', 'growing', 'among']\n",
      "\n",
      "Filtered Tokens (no stopwords):\n",
      " ['artificial', 'intelligence', 'rapidly', 'changing', 'world', 'every', 'day', 'new', 'advancements', 'made', 'machine', 'learning', 'deep', 'learning', 'technologies', 'helping', 'businesses', 'make', 'smarter', 'decisions', 'also', 'improving', 'healthcare', 'education', 'entertainment', 'industries', 'however', 'great', 'power', 'comes', 'great', 'responsibility', 'ethical', 'concerns', 'around', 'ai', 'growing', 'among', 'experts', 'general', 'public', 'climate', 'change', 'another', 'pressing', 'issue', 'scientists', 'agree', 'human', 'activities']\n",
      "\n",
      "Corrected Tokens:\n",
      " ['artificial', 'intelligence', 'rapidly', 'changing', 'world', 'every', 'day', 'new', 'advancements', 'made', 'machine', 'learning', 'deep', 'learning', 'technologies', 'helping', 'businesses', 'make', 'smarter', 'decisions', 'also', 'improving', 'healthcare', 'education', 'entertainment', 'industries', 'however', 'great', 'power', 'comes', 'great', 'responsibility', 'ethical', 'concerns', 'around', 'ai', 'growing', 'among', 'experts', 'general', 'public', 'climate', 'change', 'another', 'pressing', 'issue', 'scientists', 'agree', 'human', 'activities']\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP 22    #####################\n",
    "\n",
    "'''Write a program to read a text file with at least 30 sentences and 200 words\n",
    "and perform the following tasks in the given sequence.\n",
    "a. Text cleaning by removing punctuation/special characters, numbers\n",
    "and extra white spaces. Use regular expression for the same.\n",
    "b. Convert text to lowercase\n",
    "c. Tokenization\n",
    "d. Remove stop words\n",
    "e. Correct misspelled words'''\n",
    "\n",
    "# import re\n",
    "# import nltk\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from spellchecker import SpellChecker\n",
    "\n",
    "# # Download required NLTK data\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "\n",
    "# def clean_text(text):\n",
    "#     \"\"\"Remove punctuation, special characters, numbers, and extra whitespaces.\"\"\"\n",
    "#     text = re.sub(r'[^a-zA-Z\\s]', '', text)  # keep only letters and spaces\n",
    "#     text = re.sub(r'\\s+', ' ', text)  # replace multiple spaces with single space\n",
    "#     return text.strip()\n",
    "\n",
    "# def main():\n",
    "#     # Step 1: Get file path input from user\n",
    "#     file_path = input(\"Enter the path of the text file you want to process: \").strip()\n",
    "\n",
    "#     try:\n",
    "#         # Step 2: Read the text file\n",
    "#         with open(file_path, 'r', encoding='utf-8') as file:\n",
    "#             text = file.read()\n",
    "\n",
    "#         # Step 3: Clean the text\n",
    "#         cleaned_text = clean_text(text)\n",
    "\n",
    "#         # Step 4: Convert text to lowercase\n",
    "#         cleaned_text = cleaned_text.lower()\n",
    "\n",
    "#         # Step 5: Tokenization\n",
    "#         tokens = word_tokenize(cleaned_text)\n",
    "\n",
    "#         # Step 6: Remove stopwords\n",
    "#         stop_words = set(stopwords.words('english'))\n",
    "#         tokens_without_stopwords = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "#         # Step 7: Correct misspelled words\n",
    "#         spell = SpellChecker()\n",
    "#         corrected_tokens = [spell.correction(word) if spell.correction(word) else word for word in tokens_without_stopwords]\n",
    "\n",
    "#         # Final Output\n",
    "#         print(\"\\nCleaned and Processed Tokens:\\n\")\n",
    "#         print(corrected_tokens)\n",
    "\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Error: File not found at path '{file_path}'. Please check and try again.\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "\n",
    "\n",
    "!pip install pyspellchecker\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from spellchecker import SpellChecker\n",
    "import os\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Path to file inside \"CSV Files\" folder\n",
    "file_path = os.path.join(\"CSV Files\", r\"C:\\Users\\shank\\Downloads\\nlpTextFile.txt\")\n",
    "\n",
    "# Step a: Read and clean the text\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# Remove punctuation, numbers, and special characters\n",
    "text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "# print(\"Cleaned Text:\\n\", text[:500])  # Print first 500 characters of cleaned text\n",
    "# Step b: Convert to lowercase\n",
    "text = text.lower()\n",
    "\n",
    "# Step c: Tokenization (no sentence split to avoid punkt_tab error)\n",
    "tokens = word_tokenize(text)\n",
    "\n",
    "# Step d: Remove stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "# Step e: Correct spelling\n",
    "spell = SpellChecker()\n",
    "corrected_tokens = [spell.correction(word) for word in filtered_tokens]\n",
    "\n",
    "# Final Output\n",
    "print(\"Original Tokens:\\n\", tokens[:50])\n",
    "print(\"\\nFiltered Tokens (no stopwords):\\n\", filtered_tokens[:50])\n",
    "print(\"\\nCorrected Tokens:\\n\", corrected_tokens[:50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0mck2PqmELGc",
    "outputId": "322da5b2-a575-4748-d631-8c643b096384"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\shank\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shank\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\shank\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the path of the text file you want to process:  C:\\Users\\shank\\Downloads\\nlpTextFile.txt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned and Processed Trigrams (3 Consecutive Words) After Lemmatization:\n",
      "\n",
      "[('artificial', 'intelligence', 'rapidly'), ('intelligence', 'rapidly', 'changing'), ('rapidly', 'changing', 'world'), ('changing', 'world', 'every'), ('world', 'every', 'day'), ('every', 'day', 'new'), ('day', 'new', 'advancement'), ('new', 'advancement', 'made'), ('advancement', 'made', 'machine'), ('made', 'machine', 'learning'), ('machine', 'learning', 'deep'), ('learning', 'deep', 'learning'), ('deep', 'learning', 'technology'), ('learning', 'technology', 'helping'), ('technology', 'helping', 'business'), ('helping', 'business', 'make'), ('business', 'make', 'smarter'), ('make', 'smarter', 'decision'), ('smarter', 'decision', 'also'), ('decision', 'also', 'improving'), ('also', 'improving', 'healthcare'), ('improving', 'healthcare', 'education'), ('healthcare', 'education', 'entertainment'), ('education', 'entertainment', 'industry'), ('entertainment', 'industry', 'however'), ('industry', 'however', 'great'), ('however', 'great', 'power'), ('great', 'power', 'come'), ('power', 'come', 'great'), ('come', 'great', 'responsibility'), ('great', 'responsibility', 'ethical'), ('responsibility', 'ethical', 'concern'), ('ethical', 'concern', 'around'), ('concern', 'around', 'ai'), ('around', 'ai', 'growing'), ('ai', 'growing', 'among'), ('growing', 'among', 'expert'), ('among', 'expert', 'general'), ('expert', 'general', 'public'), ('general', 'public', 'climate'), ('public', 'climate', 'change'), ('climate', 'change', 'another'), ('change', 'another', 'pressing'), ('another', 'pressing', 'issue'), ('pressing', 'issue', 'scientist'), ('issue', 'scientist', 'agree'), ('scientist', 'agree', 'human'), ('agree', 'human', 'activity'), ('human', 'activity', 'contribute'), ('activity', 'contribute', 'significantly'), ('contribute', 'significantly', 'global'), ('significantly', 'global', 'warming'), ('global', 'warming', 'government'), ('warming', 'government', 'making'), ('government', 'making', 'effort'), ('making', 'effort', 'reduce'), ('effort', 'reduce', 'carbon'), ('reduce', 'carbon', 'emission'), ('carbon', 'emission', 'renewable'), ('emission', 'renewable', 'energy'), ('renewable', 'energy', 'source'), ('energy', 'source', 'like'), ('source', 'like', 'solar'), ('like', 'solar', 'wind'), ('solar', 'wind', 'power'), ('wind', 'power', 'becoming'), ('power', 'becoming', 'popular'), ('becoming', 'popular', 'individual'), ('popular', 'individual', 'also'), ('individual', 'also', 'adopting'), ('also', 'adopting', 'greener'), ('adopting', 'greener', 'lifestyle'), ('greener', 'lifestyle', 'help'), ('lifestyle', 'help', 'planet'), ('help', 'planet', 'space'), ('planet', 'space', 'exploration'), ('space', 'exploration', 'always'), ('exploration', 'always', 'fascinated'), ('always', 'fascinated', 'humanity'), ('fascinated', 'humanity', 'recent'), ('humanity', 'recent', 'year'), ('recent', 'year', 'private'), ('year', 'private', 'company'), ('private', 'company', 'like'), ('company', 'like', 'spacex'), ('like', 'spacex', 'blue'), ('spacex', 'blue', 'origin'), ('blue', 'origin', 'made'), ('origin', 'made', 'remarkable'), ('made', 'remarkable', 'progress'), ('remarkable', 'progress', 'mission'), ('progress', 'mission', 'mar'), ('mission', 'mar', 'longer'), ('mar', 'longer', 'distant'), ('longer', 'distant', 'dream'), ('distant', 'dream', 'scientist'), ('dream', 'scientist', 'hopeful'), ('scientist', 'hopeful', 'discovering'), ('hopeful', 'discovering', 'sign'), ('discovering', 'sign', 'life'), ('sign', 'life', 'beyond'), ('life', 'beyond', 'earth'), ('beyond', 'earth', 'world'), ('earth', 'world', 'sport'), ('world', 'sport', 'technology'), ('sport', 'technology', 'transformed'), ('technology', 'transformed', 'way'), ('transformed', 'way', 'game'), ('way', 'game', 'played'), ('game', 'played', 'watched'), ('played', 'watched', 'instant'), ('watched', 'instant', 'replay'), ('instant', 'replay', 'advanced'), ('replay', 'advanced', 'statistic'), ('advanced', 'statistic', 'virtual'), ('statistic', 'virtual', 'reality'), ('virtual', 'reality', 'training'), ('reality', 'training', 'common'), ('training', 'common', 'professional'), ('common', 'professional', 'sport'), ('professional', 'sport', 'fan'), ('sport', 'fan', 'enjoy'), ('fan', 'enjoy', 'immersive'), ('enjoy', 'immersive', 'experience'), ('immersive', 'experience', 'ever'), ('experience', 'ever', 'education'), ('ever', 'education', 'undergone'), ('education', 'undergone', 'digital'), ('undergone', 'digital', 'revolution'), ('digital', 'revolution', 'online'), ('revolution', 'online', 'learning'), ('online', 'learning', 'platform'), ('learning', 'platform', 'made'), ('platform', 'made', 'education'), ('made', 'education', 'accessible'), ('education', 'accessible', 'million'), ('accessible', 'million', 'worldwide'), ('million', 'worldwide', 'student'), ('worldwide', 'student', 'earn'), ('student', 'earn', 'degree'), ('earn', 'degree', 'without'), ('degree', 'without', 'stepping'), ('without', 'stepping', 'classroom'), ('stepping', 'classroom', 'teacher'), ('classroom', 'teacher', 'using'), ('teacher', 'using', 'smart'), ('using', 'smart', 'tool'), ('smart', 'tool', 'engage'), ('tool', 'engage', 'evaluate'), ('engage', 'evaluate', 'student'), ('evaluate', 'student', 'better'), ('student', 'better', 'meanwhile'), ('better', 'meanwhile', 'global'), ('meanwhile', 'global', 'politics'), ('global', 'politics', 'remain'), ('politics', 'remain', 'complex'), ('remain', 'complex', 'trade'), ('complex', 'trade', 'war'), ('trade', 'war', 'alliance'), ('war', 'alliance', 'conflict'), ('alliance', 'conflict', 'shape'), ('conflict', 'shape', 'life'), ('shape', 'life', 'billion'), ('life', 'billion', 'diplomacy'), ('billion', 'diplomacy', 'communication'), ('diplomacy', 'communication', 'nation'), ('communication', 'nation', 'important'), ('nation', 'important', 'ever'), ('important', 'ever', 'leader'), ('ever', 'leader', 'must'), ('leader', 'must', 'work'), ('must', 'work', 'together'), ('work', 'together', 'solve'), ('together', 'solve', 'global'), ('solve', 'global', 'challenge'), ('global', 'challenge', 'health'), ('challenge', 'health', 'wellness'), ('health', 'wellness', 'trend'), ('wellness', 'trend', 'continue'), ('trend', 'continue', 'evolve'), ('continue', 'evolve', 'people'), ('evolve', 'people', 'aware'), ('people', 'aware', 'mental'), ('aware', 'mental', 'health'), ('mental', 'health', 'past'), ('health', 'past', 'yoga'), ('past', 'yoga', 'meditation'), ('yoga', 'meditation', 'mindful'), ('meditation', 'mindful', 'living'), ('mindful', 'living', 'gaining'), ('living', 'gaining', 'popularity'), ('gaining', 'popularity', 'healthy'), ('popularity', 'healthy', 'diet'), ('healthy', 'diet', 'fitness'), ('diet', 'fitness', 'routine'), ('fitness', 'routine', 'part'), ('routine', 'part', 'daily'), ('part', 'daily', 'life'), ('daily', 'life', 'many'), ('life', 'many', 'entertainment'), ('many', 'entertainment', 'industry'), ('entertainment', 'industry', 'never'), ('industry', 'never', 'stop'), ('never', 'stop', 'evolving'), ('stop', 'evolving', 'streaming'), ('evolving', 'streaming', 'service'), ('streaming', 'service', 'like'), ('service', 'like', 'netflix'), ('like', 'netflix', 'disney'), ('netflix', 'disney', 'changed'), ('disney', 'changed', 'people'), ('changed', 'people', 'consume'), ('people', 'consume', 'medium'), ('consume', 'medium', 'bingewatching'), ('medium', 'bingewatching', 'entire'), ('bingewatching', 'entire', 'season'), ('entire', 'season', 'one'), ('season', 'one', 'weekend'), ('one', 'weekend', 'new'), ('weekend', 'new', 'normal'), ('new', 'normal', 'music'), ('normal', 'music', 'movie'), ('music', 'movie', 'game'), ('movie', 'game', 'accessible'), ('game', 'accessible', 'ever'), ('accessible', 'ever', 'city'), ('ever', 'city', 'technology'), ('city', 'technology', 'shaping'), ('technology', 'shaping', 'way'), ('shaping', 'way', 'people'), ('way', 'people', 'live'), ('people', 'live', 'smart'), ('live', 'smart', 'home'), ('smart', 'home', 'selfdriving'), ('home', 'selfdriving', 'car'), ('selfdriving', 'car', 'iot'), ('car', 'iot', 'device'), ('iot', 'device', 'promise'), ('device', 'promise', 'convenient'), ('promise', 'convenient', 'lifestyle'), ('convenient', 'lifestyle', 'yet'), ('lifestyle', 'yet', 'concern'), ('yet', 'concern', 'data'), ('concern', 'data', 'privacy'), ('data', 'privacy', 'cybersecurity'), ('privacy', 'cybersecurity', 'persist'), ('cybersecurity', 'persist', 'balancing'), ('persist', 'balancing', 'innovation'), ('balancing', 'innovation', 'safety'), ('innovation', 'safety', 'critical'), ('safety', 'critical', 'future'), ('critical', 'future', 'hold'), ('future', 'hold', 'endless'), ('hold', 'endless', 'possibility'), ('endless', 'possibility', 'scientist'), ('possibility', 'scientist', 'engineer'), ('scientist', 'engineer', 'artist'), ('engineer', 'artist', 'leader'), ('artist', 'leader', 'continue'), ('leader', 'continue', 'shape'), ('continue', 'shape', 'world'), ('shape', 'world', 'every'), ('world', 'every', 'invention'), ('every', 'invention', 'discovery'), ('invention', 'discovery', 'brings'), ('discovery', 'brings', 'humanity'), ('brings', 'humanity', 'one'), ('humanity', 'one', 'step'), ('one', 'step', 'closer'), ('step', 'closer', 'better'), ('closer', 'better', 'future'), ('better', 'future', 'exciting'), ('future', 'exciting', 'time'), ('exciting', 'time', 'alive'), ('time', 'alive', 'full'), ('alive', 'full', 'challenge'), ('full', 'challenge', 'opportunity')]\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP 23    #####################\n",
    "\n",
    "'''Write a program to read a text file with at least 30 sentences and 200 words\n",
    "and perform the following tasks in the given sequence.\n",
    "a. Text cleaning by removing punctuation/special characters, numbers\n",
    "and extra white spaces. Use regular expression for the same.\n",
    "b. Convert text to lowercase\n",
    "c. Stemming and Lemmatization\n",
    "d. Create a list of 3 consecutive words after lemmatization'''\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Remove punctuation, special characters, numbers, and extra whitespaces.\"\"\"\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Keep only letters and spaces\n",
    "    text = re.sub(r'\\s+', ' ', text)  # Replace multiple spaces with a single space\n",
    "    return text.strip()\n",
    "\n",
    "def main():\n",
    "    # Step 1: Get file path input from user\n",
    "    file_path = input(\"Enter the path of the text file you want to process: \").strip()\n",
    "\n",
    "    try:\n",
    "        # Step 2: Read the text file\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "\n",
    "        # Step 3: Clean the text\n",
    "        cleaned_text = clean_text(text)\n",
    "\n",
    "        # Step 4: Convert text to lowercase\n",
    "        cleaned_text = cleaned_text.lower()\n",
    "\n",
    "        # Step 5: Tokenization\n",
    "        tokens = word_tokenize(cleaned_text)\n",
    "\n",
    "        # Step 6: Remove stopwords\n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "        # Step 7: Stemming and Lemmatization\n",
    "        # Using PorterStemmer for stemming\n",
    "        stemmer = PorterStemmer()\n",
    "        stemmed_tokens = [stemmer.stem(word) for word in tokens]\n",
    "\n",
    "        # Using WordNetLemmatizer for lemmatization\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "        # Step 8: Create a list of 3 consecutive words (bigrams) after lemmatization\n",
    "        trigrams = list(ngrams(lemmatized_tokens, 3))\n",
    "\n",
    "        # Final Output\n",
    "        print(\"\\nCleaned and Processed Trigrams (3 Consecutive Words) After Lemmatization:\\n\")\n",
    "        print(trigrams)\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at path '{file_path}'. Please check and try again.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rIx7pO1qJEnc",
    "outputId": "256df4c4-e9d4-4828-b2d4-1dd911b3d713"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-Hot Encoding for the first 10 unique words:\n",
      "Word: a -> One-Hot Encoding: [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Word: ability -> One-Hot Encoding: [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Word: about -> One-Hot Encoding: [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Word: access -> One-Hot Encoding: [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Word: actions -> One-Hot Encoding: [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Word: advanced -> One-Hot Encoding: [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Word: advancements -> One-Hot Encoding: [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Word: advantages -> One-Hot Encoding: [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Word: agent -> One-Hot Encoding: [0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n",
      "Word: ai -> One-Hot Encoding: [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0.]\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP 24    #####################\n",
    "\n",
    "'''Write a program to read a 3 text files on any technical concept with at least\n",
    "20 sentences and 150 words. Implement one-hot encoding.\n",
    "'''\n",
    "\n",
    "\n",
    "import os\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import numpy as np\n",
    "\n",
    "folder_path=\"CSV Files\"\n",
    "\n",
    "# Define file paths relative to the folder\n",
    "file_paths = [\n",
    "    os.path.join(folder_path, r\"C:\\Users\\shank\\Downloads\\nlp3TextFilePart1.txt\"),\n",
    "    os.path.join(folder_path, r\"C:\\Users\\shank\\Downloads\\nlp3TextFilePart2.txt\"),\n",
    "    os.path.join(folder_path, r\"C:\\Users\\shank\\Downloads\\nlp3TextFilePart3.txt\")\n",
    "]\n",
    "\n",
    "# Step 1: Read and clean text from files\n",
    "texts = []\n",
    "for file_path in file_paths:\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        # Remove non-alphabetical characters and convert to lowercase\n",
    "        text = re.sub(r'[^A-Za-z\\s]', '', text).lower()\n",
    "        texts.append(text)\n",
    "\n",
    "# Combine all texts into a single list of words\n",
    "words = []\n",
    "for text in texts:\n",
    "    words.extend(text.split())\n",
    "\n",
    "# Step 2: Create a set of unique words\n",
    "unique_words = sorted(set(words))\n",
    "\n",
    "# Step 3: One-hot encoding using sklearn\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "word_matrix = encoder.fit_transform(np.array(unique_words).reshape(-1, 1))\n",
    "\n",
    "# Display the one-hot encoded matrix (show first 10 rows for brevity)\n",
    "print(\"One-Hot Encoding for the first 10 unique words:\")\n",
    "for i in range(min(10, len(unique_words))):\n",
    "    print(f\"Word: {unique_words[i]} -> One-Hot Encoding: {word_matrix[i]}\")\n",
    "\n",
    "# Optionally save the matrix to a CSV file for future reference\n",
    "# np.savetxt(\"one_hot_encoded_words.csv\", word_matrix, delimiter=\",\", fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nKk8_L0dL-Hk",
    "outputId": "56b8a322-2987-4479-e470-aac4a030f82c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names (Vocabulary):\n",
      "['ability' 'about' 'access' 'actions' 'advanced' 'advancements'\n",
      " 'advantages' 'agent' 'ai' 'algorithms' 'all' 'allowing' 'allows' 'also'\n",
      " 'amazon' 'amounts' 'an' 'analysis' 'analyzed' 'and' 'anomalies'\n",
      " 'anywhere' 'applications' 'are' 'artificial' 'as' 'authentication'\n",
      " 'automatically' 'autonomous' 'aws' 'azure' 'based' 'be' 'being'\n",
      " 'benefits' 'best' 'bias' 'box' 'businesses' 'by' 'can' 'categorized'\n",
      " 'challenges' 'characteristics' 'charts' 'classified' 'classify' 'cleaned'\n",
      " 'cleaning' 'cloud' 'collaboration' 'common' 'communicate' 'complex'\n",
      " 'computer' 'computers' 'computing' 'concern' 'constantly' 'correcting'\n",
      " 'cost' 'costeffective' 'critical' 'customers' 'data' 'deals' 'decision'\n",
      " 'decisions' 'deep' 'delivers' 'delivery' 'descriptive' 'despite'\n",
      " 'developing' 'deviation' 'discover' 'down' 'driving' 'duplicates'\n",
      " 'easily' 'eda' 'effective' 'effectively' 'efficiency' 'enables'\n",
      " 'encryption' 'errors' 'essential' 'excel' 'explicitly' 'exploratory'\n",
      " 'face' 'findings' 'firewalls' 'flexibility' 'following' 'for' 'forests'\n",
      " 'from' 'generalizations' 'google' 'graphs' 'hand' 'handling' 'hardware'\n",
      " 'has' 'help' 'helps' 'histograms' 'however' 'iaas' 'identify' 'image'\n",
      " 'implement' 'improve' 'improving' 'in' 'include' 'individuals' 'industry'\n",
      " 'inferential' 'information' 'informed' 'infrastructure' 'inspecting'\n",
      " 'intelligence' 'internet' 'interpretability' 'into' 'involves' 'is' 'it'\n",
      " 'its' 'key' 'labeled' 'lack' 'language' 'languages' 'large' 'layers'\n",
      " 'learn' 'learning' 'like' 'machine' 'machines' 'main' 'major' 'make'\n",
      " 'making' 'many' 'mean' 'measures' 'median' 'methods' 'microsoft'\n",
      " 'missing' 'model' 'modeling' 'models' 'most' 'multifactor' 'must'\n",
      " 'natural' 'needs' 'networks' 'neural' 'of' 'offer' 'offers' 'often' 'on'\n",
      " 'once' 'one' 'or' 'organizations' 'other' 'over' 'overfitting' 'own'\n",
      " 'owning' 'paas' 'part' 'particularly' 'passwords' 'patterns'\n",
      " 'performance' 'performed' 'physical' 'platform' 'platforms' 'plots'\n",
      " 'population' 'power' 'practices' 'predictions' 'process' 'processing'\n",
      " 'programmed' 'programming' 'protect' 'providers' 'provides' 'providing'\n",
      " 'punishing' 'python' 'quickly' 'random' 'range' 'recognition'\n",
      " 'reinforcement' 'reliable' 'removing' 'reports' 'researchers' 'resources'\n",
      " 'responsibility' 'results' 'revolutionized' 'rewarding' 'saas' 'sample'\n",
      " 'savings' 'scalability' 'scale' 'scatter' 'science' 'securing' 'security'\n",
      " 'sequences' 'service' 'services' 'set' 'shared' 'sizes' 'software'\n",
      " 'speech' 'sql' 'standard' 'statistical' 'statistics' 'step' 'still'\n",
      " 'storage' 'strong' 'subset' 'such' 'summarize' 'supervised' 'support'\n",
      " 'systems' 'take' 'tasks' 'techniques' 'that' 'the' 'their' 'these'\n",
      " 'three' 'through' 'to' 'tools' 'trained' 'training' 'trees' 'types'\n",
      " 'uncover' 'unlabeled' 'unsupervised' 'up' 'use' 'used' 'useful' 'users'\n",
      " 'uses' 'using' 'various' 'vector' 'virtualized' 'vision' 'visualized'\n",
      " 'visualizing' 'web' 'while' 'with' 'without' 'working' 'world']\n",
      "\n",
      "Bag of Words Matrix:\n",
      "[[ 1  0  0  1  0  1  0  1  1  2  0  0  1  0  0  1  1  0  0  7  0  0  1  2\n",
      "   2  2  0  1  1  0  0  0  1  1  1  0  1  0  0  1  3  0  1  0  0  1  0  0\n",
      "   0  0  0  1  0  1  1  1  0  0  1  0  0  0  0  0  4  1  1  1  2  0  0  0\n",
      "   1  0  0  0  0  1  0  0  0  1  0  0  1  0  0  0  0  1  0  1  0  0  0  0\n",
      "   0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  1  1  0  1  1  3  1  0  0\n",
      "   0  0  0  0  0  1  0  1  1  1  5  2  1  1  1  1  1  0  1  1  1 13  1  6\n",
      "   1  0  0  2  0  1  0  0  0  1  0  0  2  0  2  1  0  0  1  0  3  2  7  0\n",
      "   0  0  1  0  1  1  0  0  0  1  0  0  0  0  1  0  2  1  0  0  0  0  0  0\n",
      "   0  0  1  1  1  1  0  0  0  0  0  1  0  1  1  0  2  2  0  0  0  1  0  0\n",
      "   0  0  1  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  0  1  0\n",
      "   0  1  0  0  2  2  0  2  1  1  0  1  0  2  3  1  2  0  0  5  0  1  1  1\n",
      "   0  0  1  2  0  1  1  0  0  1  1  0  1  0  1  0  0  0  1  2  1  1  0]\n",
      " [ 0  1  0  0  1  0  0  0  0  1  0  0  0  1  0  0  1  7  1  9  1  0  0  1\n",
      "   0  2  0  0  0  0  0  1  1  0  0  0  0  1  0  0  1  0  0  1  1  0  1  1\n",
      "   2  0  0  0  1  0  0  0  0  0  0  1  0  0  1  0 17  0  0  1  0  0  0  2\n",
      "   0  0  1  1  0  0  1  0  2  0  1  0  0  0  1  1  1  0  1  0  1  0  0  0\n",
      "   0  0  0  1  0  1  1  1  0  0  1  1  1  0  0  0  0  0  0  0  3  0  0  0\n",
      "   2  1  1  0  1  0  0  0  0  4  5  3  0  0  0  0  0  1  0  0  0  1  3  1\n",
      "   0  0  0  2  1  0  1  0  1  0  0  1  0  1  1  0  0  0  0  0  0  0  4  0\n",
      "   0  2  2  1  0  4  1  1  0  0  0  0  0  1  0  0  1  0  1  0  0  0  3  1\n",
      "   0  0  2  1  0  0  1  0  0  0  0  0  1  0  0  0  0  0  0  1  1  0  0  0\n",
      "   1  0  0  0  1  0  0  0  1  1  0  0  0  0  0  1  0  0  0  0  1  1  0  4\n",
      "   1  0  0  0  0  2  1  0  0  0  0  0  2  1  7  0  0  0  1  4  1  0  0  0\n",
      "   0  1  0  0  0  0  0  1  0  0  3  2  0  0  0  1  1  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  0  1  0  0  0  1  1  1  2  1  0  0  0  0 10  0  1  3  1\n",
      "   0  4  1  0  0  1  1  1  0  0  0  1  0  0  2  2  0  1  0  0  0  0  0  0\n",
      "   0  8  1  0  0  0  0  0  8  1  0  0  1  1  1  1  3  0  0  0  0  1  1  0\n",
      "   0  1  0  0  1  0  0  1  0  0  0  1  2  1  0  0  0  0  0  0  0  1  1  1\n",
      "   3  0  1  0  1  0  0  0  1  1  0  0  0  1  2  0  0  1  0  0  2  0  1  1\n",
      "   0  0  0  1  0  0  2  0  1  0  4  3  0  0  0  0  0  0  0  0  0  0  1  0\n",
      "   0  1  1  0  0  0  0  1  0  0  1  0  0  0  0  0  1  1  0  1  0  0  5  1\n",
      "   1  0  1  0  1  1  0  1  2  0  1  1  2  0  0  1  0  0  0  1  2  1  0  0\n",
      "   1  1  0  0  1  0  0  1  2  1  1  0  0  0  0  1  0  0  1  0  0  0  1  1\n",
      "   0  1  0  2  0  1  1  1  0  0  1  2  0  3  3  0  1  1  3  0  0  0  0  0\n",
      "   0  0  1  1  0  1  0  0  0  0  1  0  0  1  6  2  0  1  0  4  0  0  0  0\n",
      "   1  0  0  0  1  0  0  0  2  0  1  0  0  1  0  0  0  1  0  0  1  0  1]]\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP 25    #####################\n",
    "\n",
    "#3 text files on a movie review with at least 20 sentences and 150 words. Implement bag of words.\n",
    "\"\"\"Write a program to read a 3 text files on a movie review with at least 20\n",
    "sentences and 150 words. Implement bag of words. \"\"\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Folder where your 3 text files are stored\n",
    "folder_path = os.path.join(\"CSV Files\")\n",
    "\n",
    "# List to store text from selected review files\n",
    "documents = []\n",
    "\n",
    "# Specify only the 3 review file names you want\n",
    "review_files = [r\"C:\\Users\\shank\\Downloads\\nlp3TextFilePart1.txt\", r\"C:\\Users\\shank\\Downloads\\nlp3TextFilePart2.txt\", r\"C:\\Users\\shank\\Downloads\\nlp3TextFilePart3.txt\"]\n",
    "\n",
    "# Read each review file\n",
    "for filename in review_files:\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if os.path.exists(file_path):  # Check if file actually exists\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            # Clean text: remove special characters and extra spaces\n",
    "            text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "            text = re.sub(r'\\s+', ' ', text)\n",
    "            text = text.lower()\n",
    "            documents.append(text)\n",
    "    else:\n",
    "        print(f\"Warning: {filename} not found!\")\n",
    "\n",
    "# Step 2: Bag of Words using CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Step 3: Show Results\n",
    "print(\"Feature Names (Vocabulary):\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"\\nBag of Words Matrix:\")\n",
    "print(X.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hlv-7Al6M6v-",
    "outputId": "8a5bc3b1-6790-4430-a056-144274d2b524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Names (Vocabulary):\n",
      "['ability' 'about' 'access' 'actions' 'advanced' 'advancements'\n",
      " 'advantages' 'agent' 'ai' 'algorithms' 'all' 'allowing' 'allows' 'also'\n",
      " 'amazon' 'amounts' 'an' 'analysis' 'analyzed' 'and' 'anomalies'\n",
      " 'anywhere' 'applications' 'are' 'artificial' 'as' 'authentication'\n",
      " 'automatically' 'autonomous' 'aws' 'azure' 'based' 'be' 'being'\n",
      " 'benefits' 'best' 'bias' 'box' 'businesses' 'by' 'can' 'categorized'\n",
      " 'challenges' 'characteristics' 'charts' 'classified' 'classify' 'cleaned'\n",
      " 'cleaning' 'cloud' 'collaboration' 'common' 'communicate' 'complex'\n",
      " 'computer' 'computers' 'computing' 'concern' 'constantly' 'correcting'\n",
      " 'cost' 'costeffective' 'critical' 'customers' 'data' 'deals' 'decision'\n",
      " 'decisions' 'deep' 'delivers' 'delivery' 'descriptive' 'despite'\n",
      " 'developing' 'deviation' 'discover' 'down' 'driving' 'duplicates'\n",
      " 'easily' 'eda' 'effective' 'effectively' 'efficiency' 'enables'\n",
      " 'encryption' 'errors' 'essential' 'excel' 'explicitly' 'exploratory'\n",
      " 'face' 'findings' 'firewalls' 'flexibility' 'following' 'for' 'forests'\n",
      " 'from' 'generalizations' 'google' 'graphs' 'hand' 'handling' 'hardware'\n",
      " 'has' 'help' 'helps' 'histograms' 'however' 'iaas' 'identify' 'image'\n",
      " 'implement' 'improve' 'improving' 'in' 'include' 'individuals' 'industry'\n",
      " 'inferential' 'information' 'informed' 'infrastructure' 'inspecting'\n",
      " 'intelligence' 'internet' 'interpretability' 'into' 'involves' 'is' 'it'\n",
      " 'its' 'key' 'labeled' 'lack' 'language' 'languages' 'large' 'layers'\n",
      " 'learn' 'learning' 'like' 'machine' 'machines' 'main' 'major' 'make'\n",
      " 'making' 'many' 'mean' 'measures' 'median' 'methods' 'microsoft'\n",
      " 'missing' 'model' 'modeling' 'models' 'most' 'multifactor' 'must'\n",
      " 'natural' 'needs' 'networks' 'neural' 'of' 'offer' 'offers' 'often' 'on'\n",
      " 'once' 'one' 'or' 'organizations' 'other' 'over' 'overfitting' 'own'\n",
      " 'owning' 'paas' 'part' 'particularly' 'passwords' 'patterns'\n",
      " 'performance' 'performed' 'physical' 'platform' 'platforms' 'plots'\n",
      " 'population' 'power' 'practices' 'predictions' 'process' 'processing'\n",
      " 'programmed' 'programming' 'protect' 'providers' 'provides' 'providing'\n",
      " 'punishing' 'python' 'quickly' 'random' 'range' 'recognition'\n",
      " 'reinforcement' 'reliable' 'removing' 'reports' 'researchers' 'resources'\n",
      " 'responsibility' 'results' 'revolutionized' 'rewarding' 'saas' 'sample'\n",
      " 'savings' 'scalability' 'scale' 'scatter' 'science' 'securing' 'security'\n",
      " 'sequences' 'service' 'services' 'set' 'shared' 'sizes' 'software'\n",
      " 'speech' 'sql' 'standard' 'statistical' 'statistics' 'step' 'still'\n",
      " 'storage' 'strong' 'subset' 'such' 'summarize' 'supervised' 'support'\n",
      " 'systems' 'take' 'tasks' 'techniques' 'that' 'the' 'their' 'these'\n",
      " 'three' 'through' 'to' 'tools' 'trained' 'training' 'trees' 'types'\n",
      " 'uncover' 'unlabeled' 'unsupervised' 'up' 'use' 'used' 'useful' 'users'\n",
      " 'uses' 'using' 'various' 'vector' 'virtualized' 'vision' 'visualized'\n",
      " 'visualizing' 'web' 'while' 'with' 'without' 'working' 'world']\n",
      "\n",
      "TF-IDF Matrix:\n",
      "[[0.05422108 0.         0.         0.05422108 0.         0.05422108\n",
      "  0.         0.05422108 0.05422108 0.08247305 0.         0.\n",
      "  0.04123653 0.         0.         0.05422108 0.04123653 0.\n",
      "  0.         0.22416689 0.         0.         0.04123653 0.06404768\n",
      "  0.10844215 0.06404768 0.         0.05422108 0.05422108 0.\n",
      "  0.         0.         0.04123653 0.05422108 0.05422108 0.\n",
      "  0.05422108 0.         0.         0.04123653 0.12370958 0.\n",
      "  0.05422108 0.         0.         0.05422108 0.         0.\n",
      "  0.         0.         0.         0.05422108 0.         0.05422108\n",
      "  0.05422108 0.05422108 0.         0.         0.05422108 0.\n",
      "  0.         0.         0.         0.         0.12809537 0.05422108\n",
      "  0.05422108 0.04123653 0.10844215 0.         0.         0.\n",
      "  0.05422108 0.         0.         0.         0.         0.05422108\n",
      "  0.         0.         0.         0.05422108 0.         0.\n",
      "  0.04123653 0.         0.         0.         0.         0.05422108\n",
      "  0.         0.05422108 0.         0.         0.         0.\n",
      "  0.         0.05422108 0.04123653 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.05422108 0.05422108 0.\n",
      "  0.05422108 0.05422108 0.09607152 0.05422108 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.05422108\n",
      "  0.         0.05422108 0.04123653 0.04123653 0.16011921 0.06404768\n",
      "  0.05422108 0.05422108 0.05422108 0.05422108 0.05422108 0.\n",
      "  0.05422108 0.05422108 0.05422108 0.53607485 0.03202384 0.24741916\n",
      "  0.05422108 0.         0.         0.08247305 0.         0.05422108\n",
      "  0.         0.         0.         0.05422108 0.         0.\n",
      "  0.10844215 0.         0.08247305 0.05422108 0.         0.\n",
      "  0.05422108 0.         0.16266323 0.10844215 0.22416689 0.\n",
      "  0.         0.         0.03202384 0.         0.04123653 0.03202384\n",
      "  0.         0.         0.         0.05422108 0.         0.\n",
      "  0.         0.         0.05422108 0.         0.08247305 0.05422108\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04123653 0.04123653 0.04123653 0.05422108\n",
      "  0.         0.         0.         0.         0.         0.05422108\n",
      "  0.         0.05422108 0.05422108 0.         0.10844215 0.10844215\n",
      "  0.         0.         0.         0.05422108 0.         0.\n",
      "  0.         0.         0.05422108 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.05422108 0.         0.         0.         0.         0.\n",
      "  0.         0.05422108 0.         0.         0.05422108 0.\n",
      "  0.         0.05422108 0.         0.         0.10844215 0.06404768\n",
      "  0.         0.10844215 0.05422108 0.05422108 0.         0.05422108\n",
      "  0.         0.06404768 0.09607152 0.04123653 0.10844215 0.\n",
      "  0.         0.16011921 0.         0.05422108 0.05422108 0.05422108\n",
      "  0.         0.         0.05422108 0.10844215 0.         0.05422108\n",
      "  0.05422108 0.         0.         0.05422108 0.03202384 0.\n",
      "  0.05422108 0.         0.05422108 0.         0.         0.\n",
      "  0.05422108 0.10844215 0.04123653 0.05422108 0.        ]\n",
      " [0.         0.05177501 0.         0.         0.05177501 0.\n",
      "  0.         0.         0.         0.03937623 0.         0.\n",
      "  0.         0.03937623 0.         0.         0.03937623 0.36242507\n",
      "  0.05177501 0.27521239 0.05177501 0.         0.         0.03057915\n",
      "  0.         0.06115831 0.         0.         0.         0.\n",
      "  0.         0.03937623 0.03937623 0.         0.         0.\n",
      "  0.         0.05177501 0.         0.         0.03937623 0.\n",
      "  0.         0.05177501 0.05177501 0.         0.05177501 0.05177501\n",
      "  0.10355002 0.         0.         0.         0.05177501 0.\n",
      "  0.         0.         0.         0.         0.         0.05177501\n",
      "  0.         0.         0.03937623 0.         0.51984563 0.\n",
      "  0.         0.03937623 0.         0.         0.         0.10355002\n",
      "  0.         0.         0.05177501 0.05177501 0.         0.\n",
      "  0.05177501 0.         0.10355002 0.         0.05177501 0.\n",
      "  0.         0.         0.05177501 0.05177501 0.05177501 0.\n",
      "  0.05177501 0.         0.05177501 0.         0.         0.\n",
      "  0.         0.         0.         0.05177501 0.         0.05177501\n",
      "  0.05177501 0.05177501 0.         0.         0.05177501 0.05177501\n",
      "  0.05177501 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.09173746 0.         0.         0.\n",
      "  0.10355002 0.05177501 0.05177501 0.         0.05177501 0.\n",
      "  0.         0.         0.         0.15750492 0.15289577 0.09173746\n",
      "  0.         0.         0.         0.         0.         0.05177501\n",
      "  0.         0.         0.         0.03937623 0.09173746 0.03937623\n",
      "  0.         0.         0.         0.07875246 0.05177501 0.\n",
      "  0.05177501 0.         0.05177501 0.         0.         0.05177501\n",
      "  0.         0.05177501 0.03937623 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.12231662 0.\n",
      "  0.         0.10355002 0.06115831 0.05177501 0.         0.12231662\n",
      "  0.05177501 0.03937623 0.         0.         0.         0.\n",
      "  0.         0.05177501 0.         0.         0.03937623 0.\n",
      "  0.05177501 0.         0.         0.         0.15532503 0.05177501\n",
      "  0.         0.         0.07875246 0.03937623 0.         0.\n",
      "  0.05177501 0.         0.         0.         0.         0.\n",
      "  0.05177501 0.         0.         0.         0.         0.\n",
      "  0.         0.05177501 0.05177501 0.         0.         0.\n",
      "  0.05177501 0.         0.         0.         0.05177501 0.\n",
      "  0.         0.         0.05177501 0.05177501 0.         0.\n",
      "  0.         0.         0.         0.05177501 0.         0.\n",
      "  0.         0.         0.05177501 0.05177501 0.         0.20710004\n",
      "  0.05177501 0.         0.         0.         0.         0.06115831\n",
      "  0.05177501 0.         0.         0.         0.         0.\n",
      "  0.10355002 0.03057915 0.21405408 0.         0.         0.\n",
      "  0.05177501 0.12231662 0.05177501 0.         0.         0.\n",
      "  0.         0.05177501 0.         0.         0.         0.\n",
      "  0.         0.05177501 0.         0.         0.09173746 0.10355002\n",
      "  0.         0.         0.         0.05177501 0.05177501 0.\n",
      "  0.         0.         0.         0.         0.        ]\n",
      " [0.         0.         0.10223708 0.         0.         0.\n",
      "  0.05111854 0.         0.         0.         0.05111854 0.05111854\n",
      "  0.03887697 0.07775393 0.05111854 0.         0.         0.\n",
      "  0.         0.30191432 0.         0.05111854 0.1166309  0.03019143\n",
      "  0.         0.12076573 0.05111854 0.         0.         0.05111854\n",
      "  0.05111854 0.03887697 0.         0.         0.         0.05111854\n",
      "  0.         0.         0.10223708 0.07775393 0.         0.05111854\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.40894831 0.05111854 0.         0.         0.\n",
      "  0.         0.         0.40894831 0.05111854 0.         0.\n",
      "  0.05111854 0.05111854 0.03887697 0.05111854 0.0905743  0.\n",
      "  0.         0.         0.         0.05111854 0.05111854 0.\n",
      "  0.         0.05111854 0.         0.         0.05111854 0.\n",
      "  0.         0.05111854 0.         0.         0.         0.05111854\n",
      "  0.07775393 0.05111854 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.05111854 0.05111854 0.05111854\n",
      "  0.15335562 0.         0.03887697 0.         0.05111854 0.\n",
      "  0.         0.         0.05111854 0.05111854 0.         0.\n",
      "  0.         0.05111854 0.10223708 0.         0.         0.05111854\n",
      "  0.         0.         0.06038286 0.         0.05111854 0.05111854\n",
      "  0.         0.         0.         0.05111854 0.         0.\n",
      "  0.10223708 0.         0.03887697 0.         0.12076573 0.0905743\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.03019143 0.\n",
      "  0.         0.05111854 0.05111854 0.         0.         0.\n",
      "  0.         0.05111854 0.         0.         0.05111854 0.\n",
      "  0.         0.         0.         0.         0.05111854 0.05111854\n",
      "  0.         0.05111854 0.         0.         0.15095716 0.05111854\n",
      "  0.05111854 0.         0.03019143 0.         0.03887697 0.03019143\n",
      "  0.         0.03887697 0.10223708 0.         0.05111854 0.05111854\n",
      "  0.10223708 0.         0.         0.05111854 0.         0.\n",
      "  0.         0.05111854 0.10223708 0.05111854 0.         0.\n",
      "  0.05111854 0.05111854 0.         0.         0.03887697 0.\n",
      "  0.         0.05111854 0.10223708 0.05111854 0.05111854 0.\n",
      "  0.         0.         0.         0.05111854 0.         0.\n",
      "  0.05111854 0.         0.         0.         0.05111854 0.05111854\n",
      "  0.         0.05111854 0.         0.10223708 0.         0.05111854\n",
      "  0.05111854 0.05111854 0.         0.         0.05111854 0.10223708\n",
      "  0.         0.15335562 0.15335562 0.         0.05111854 0.05111854\n",
      "  0.15335562 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.05111854 0.05111854 0.         0.03019143\n",
      "  0.         0.         0.         0.         0.05111854 0.\n",
      "  0.         0.03019143 0.18114859 0.07775393 0.         0.05111854\n",
      "  0.         0.12076573 0.         0.         0.         0.\n",
      "  0.05111854 0.         0.         0.         0.05111854 0.\n",
      "  0.         0.         0.10223708 0.         0.03019143 0.\n",
      "  0.         0.05111854 0.         0.         0.         0.05111854\n",
      "  0.         0.         0.03887697 0.         0.05111854]]\n"
     ]
    }
   ],
   "source": [
    "#########################    EXP 26    #####################\n",
    "\n",
    "#Write a program to read a 3 text files a tourist place with at least 20 sentences and 150 words. Implement TF-IDF.\n",
    "\n",
    "import os\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Folder where your 3 text files are stored\n",
    "folder_path = os.path.join(\"CSV Files\")\n",
    "\n",
    "# List to store text from selected tourist place files\n",
    "documents = []\n",
    "\n",
    "# Specify only the 3 review file names you want\n",
    "tourist_files = [r\"C:\\Users\\shank\\Downloads\\nlp3TextFilePart1.txt\", r\"C:\\Users\\shank\\Downloads\\nlp3TextFilePart2.txt\", r\"C:\\Users\\shank\\Downloads\\nlp3TextFilePart3.txt\"]\n",
    "\n",
    "# Read each tourist file\n",
    "for filename in tourist_files:\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    if os.path.exists(file_path):  # Check if file actually exists\n",
    "        with open(file_path, 'r', encoding='utf-8') as file:\n",
    "            text = file.read()\n",
    "            # Clean text: remove special characters and extra spaces\n",
    "            text = re.sub(r'[^A-Za-z\\s]', '', text)\n",
    "            text = re.sub(r'\\s+', ' ', text)\n",
    "            text = text.lower()\n",
    "            documents.append(text)\n",
    "    else:\n",
    "        print(f\"Warning: {filename} not found!\")\n",
    "\n",
    "# Step 2: TF-IDF using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(documents)\n",
    "\n",
    "# Step 3: Show Results\n",
    "print(\"Feature Names (Vocabulary):\")\n",
    "print(vectorizer.get_feature_names_out())\n",
    "\n",
    "print(\"\\nTF-IDF Matrix:\")\n",
    "print(X.toarray())\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
